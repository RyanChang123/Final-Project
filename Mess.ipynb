{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7317b2-aad6-4ec1-962f-1b807d6d478e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ticker       2020_NI       2021_NI       2022_NI       2023_NI  \\\n",
      "0       A  7.190000e+08  1.210000e+09  1.254000e+09  1.240000e+09   \n",
      "1      AA -1.700000e+08  4.290000e+08 -1.230000e+08 -6.510000e+08   \n",
      "2     AAL -8.885000e+09 -1.993000e+09  1.270000e+08  8.220000e+08   \n",
      "3    AAME  1.216900e+07  4.281000e+06  1.525000e+06           NaN   \n",
      "4     AAN -2.659120e+08  1.099340e+08 -5.280000e+06  2.823000e+06   \n",
      "5    AAOI -5.845200e+07 -5.416200e+07 -6.639700e+07 -5.604800e+07   \n",
      "6    AAON  7.900900e+07  5.875800e+07  1.003760e+08  1.776230e+08   \n",
      "7     AAP  4.930210e+08  5.966150e+08  4.644020e+08  2.973500e+07   \n",
      "8    AAPL  5.741100e+10  9.468000e+10  9.980300e+10  9.699500e+10   \n",
      "9     AAT  3.558800e+07  3.659300e+07  5.587700e+07  6.469000e+07   \n",
      "10   ABBV  4.616000e+09  1.154200e+10  1.183600e+10  4.863000e+09   \n",
      "11   ABCB  2.619880e+08  3.769130e+08  3.465400e+08  2.691050e+08   \n",
      "12   ABEO -8.423400e+07 -8.493600e+07 -3.969600e+07 -5.418800e+07   \n",
      "13    ABG  2.544000e+08  5.324000e+08  9.973000e+08  6.025000e+08   \n",
      "14   ABIO -9.738000e+06 -1.932200e+07 -9.926000e+06 -5.339000e+06   \n",
      "15    ABM  3.000000e+05  1.263000e+08  2.304000e+08  2.513000e+08   \n",
      "16   ABMD           NaN  2.255250e+08  1.365050e+08           NaN   \n",
      "17    ABR  1.709490e+08  3.393000e+08  3.257830e+08  3.714340e+08   \n",
      "18    ABT  4.495000e+09  7.071000e+09  6.933000e+09  5.723000e+09   \n",
      "19     AC  1.881600e+07  5.920300e+07 -4.890700e+07  3.745100e+07   \n",
      "20    ACA  1.066000e+08  6.960000e+07  2.458000e+08  1.592000e+08   \n",
      "21   ACAD -2.815840e+08 -1.678700e+08 -2.159750e+08 -6.128600e+07   \n",
      "22   ACCO  6.200000e+07  1.019000e+08 -1.320000e+07 -2.180000e+07   \n",
      "23   ACGL  1.405521e+09  2.157000e+09  1.476000e+09  4.443000e+09   \n",
      "24   ACHC -6.721320e+08  1.906350e+08  2.731390e+08 -2.166700e+07   \n",
      "25   ACHV -1.473000e+07 -3.315200e+07 -4.235000e+07 -2.981500e+07   \n",
      "26   ACIW  7.266000e+07  1.277910e+08  1.421770e+08  1.215090e+08   \n",
      "27   ACLS  4.998200e+07  9.865000e+07  1.830790e+08  2.462630e+08   \n",
      "28    ACM -1.863700e+08  1.731850e+08  3.106110e+08  5.533200e+07   \n",
      "29   ACMR  1.878000e+07  3.775700e+07  3.926300e+07  7.734900e+07   \n",
      "30    ACN  5.107839e+09  5.906809e+09  6.877169e+09  6.871557e+09   \n",
      "31   ACNB  1.839400e+07  2.783400e+07  3.575200e+07  3.168800e+07   \n",
      "32   ACOR -9.959400e+07 -1.039540e+08 -6.591600e+07 -2.528540e+08   \n",
      "33   ACRE  2.184000e+07  6.046000e+07  2.978500e+07 -3.886700e+07   \n",
      "34   ACRS -5.101500e+07 -9.086500e+07 -8.690800e+07 -8.848100e+07   \n",
      "35   ACTG  1.092310e+08  1.491970e+08 -1.250650e+08  6.706000e+07   \n",
      "36    ACU  8.098766e+06  1.365568e+07  3.034766e+06  1.779316e+07   \n",
      "37   ADBE  5.260000e+09  4.822000e+09  4.756000e+09  5.428000e+09   \n",
      "38    ADC  9.138100e+07  1.222730e+08  1.524370e+08  1.699590e+08   \n",
      "39    ADI  1.220761e+09  1.390422e+09  2.748561e+09  3.314579e+09   \n",
      "40    ADM  1.772000e+09  2.709000e+09  4.340000e+09  3.483000e+09   \n",
      "41   ADMA -7.574855e+07 -7.164800e+07 -6.590400e+07 -2.823900e+07   \n",
      "42   ADNT -5.470000e+08  1.108000e+09 -1.200000e+08  2.050000e+08   \n",
      "43    ADP  2.466500e+09  2.598500e+09  2.948900e+09  3.412000e+09   \n",
      "44   ADSK           NaN  1.208000e+09  4.970000e+08  8.230000e+08   \n",
      "45    ADT -6.321930e+08 -3.408200e+08  1.326630e+08  4.630090e+08   \n",
      "46   ADTN  2.378000e+06 -8.635000e+06 -2.037000e+06 -2.676880e+08   \n",
      "47   ADUS  3.313300e+07  4.512600e+07  4.602500e+07  6.251600e+07   \n",
      "48   ADVM -1.175070e+08 -1.455400e+08 -1.545360e+08 -1.171650e+08   \n",
      "49   ADXS -3.014600e+07 -4.025400e+07 -3.801300e+07 -4.807200e+07   \n",
      "\n",
      "    2020_2021_NI_Grow  2021_2022_NI_Grow  2022_2023_NI_Grow    2023_PE  \n",
      "0        4.910000e+08       4.400000e+07      -1.400000e+07  22.840984  \n",
      "1        5.990000e+08      -5.520000e+08      -5.280000e+08  15.779736  \n",
      "2        6.892000e+09       2.120000e+09       6.950000e+08   4.311526  \n",
      "3       -7.888000e+06      -2.756000e+06                NaN        NaN  \n",
      "4        3.758460e+08      -1.152140e+08       8.103000e+06  10.367647  \n",
      "5        4.290000e+06      -1.223500e+07       1.034900e+07  11.586206  \n",
      "6       -2.025100e+07       4.161800e+07       7.724700e+07  32.457336  \n",
      "7        1.035940e+08      -1.322130e+08      -4.346670e+08  16.606743  \n",
      "8        3.726900e+10       5.123000e+09      -2.808000e+09  26.229730  \n",
      "9        1.005000e+06       1.928400e+07       8.813000e+06  29.678083  \n",
      "10       6.926000e+09       2.940000e+08      -6.973000e+09  13.418113  \n",
      "11       1.149250e+08      -3.037300e+07      -7.743500e+07   9.824131  \n",
      "12      -7.020000e+05       4.524000e+07      -1.449200e+07  -2.042474  \n",
      "13       2.780000e+08       4.649000e+08      -3.948000e+08   6.843219  \n",
      "14      -9.584000e+06       9.396000e+06       4.587000e+06  -0.402932  \n",
      "15       1.260000e+08       1.041000e+08       2.090000e+07  12.142266  \n",
      "16                NaN      -8.902000e+07                NaN  60.768738  \n",
      "17       1.683510e+08      -1.351700e+07       4.565100e+07   7.581871  \n",
      "18       2.576000e+09      -1.380000e+08      -1.210000e+09  20.742218  \n",
      "19       4.038700e+07      -1.081100e+08       8.635800e+07  12.413129  \n",
      "20      -3.700000e+07       1.762000e+08      -8.660000e+07  19.806122  \n",
      "21       1.137140e+08      -4.810500e+07       1.546890e+08  13.519841  \n",
      "22       3.990000e+07      -1.151000e+08      -8.600000e+06   3.900000  \n",
      "23       7.514790e+08      -6.810000e+08       2.967000e+09  10.694670  \n",
      "24       8.627670e+08       8.250400e+07      -2.948060e+08  18.374690  \n",
      "25      -1.842200e+07      -9.198000e+06       1.253500e+07  -4.977778  \n",
      "26       5.513100e+07       1.438600e+07      -2.066800e+07  20.766080  \n",
      "27       4.866800e+07       8.442900e+07       6.318400e+07  12.484561  \n",
      "28       3.595550e+08       1.374260e+08      -2.552790e+08  18.614645  \n",
      "29       1.897700e+07       1.506000e+06       3.808600e+07  14.302702  \n",
      "30       7.989700e+08       9.703600e+08      -5.612000e+06  23.008537  \n",
      "31       9.440000e+06       7.918000e+06      -4.064000e+06   9.374914  \n",
      "32      -4.360000e+06       3.803800e+07      -1.869380e+08  -0.688542  \n",
      "33       3.862000e+07      -3.067500e+07      -6.865200e+07   8.765822  \n",
      "34      -3.985000e+07       3.957000e+06      -1.573000e+06  -1.481707  \n",
      "35       3.996600e+07      -2.742620e+08       1.921250e+08   8.431034  \n",
      "36       5.556913e+06      -1.062091e+07       1.475839e+07  15.772201  \n",
      "37      -4.380000e+08      -6.600000e+07       6.720000e+08  24.831842  \n",
      "38       3.089200e+07       3.016400e+07       1.752200e+07  30.868280  \n",
      "39       1.696610e+08       1.358139e+09       5.660180e+08  26.884410  \n",
      "40       9.370000e+08       1.631000e+09      -8.570000e+08  10.214036  \n",
      "41       4.100548e+06       5.744000e+06       3.766500e+07  13.250000  \n",
      "42       1.655000e+09      -1.228000e+09       3.250000e+08   7.579747  \n",
      "43       1.320000e+08       3.504000e+08       4.631000e+08  24.383999  \n",
      "44                NaN      -7.110000e+08       3.260000e+08  23.856203  \n",
      "45       2.913730e+08       4.734830e+08       3.303460e+08   7.652941  \n",
      "46      -1.101300e+07       6.598000e+06      -2.656510e+08  11.657894  \n",
      "47       1.199300e+07       8.990000e+05       1.649100e+07  17.815588  \n",
      "48      -2.803300e+07      -8.996000e+06       3.737100e+07  -1.906078  \n",
      "49      -1.010800e+07       2.241000e+06      -1.005900e+07  -0.910959  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv(\"modified_net_income_data.csv\")\n",
    "\n",
    "# Filter the dataset to only include the first 50 tickers\n",
    "data = data.head(50)\n",
    "\n",
    "# Function to get forward PE ratio from Yahoo Finance\n",
    "def get_forward_pe(ticker):\n",
    "    try:\n",
    "        # Fetch ticker data from Yahoo Finance\n",
    "        ticker_data = yf.Ticker(ticker)\n",
    "        # Get forward PE ratio\n",
    "        forward_pe = ticker_data.info['forwardPE']\n",
    "        return forward_pe\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create the new column\n",
    "data['2023_PE'] = data['Ticker'].apply(get_forward_pe)\n",
    "\n",
    "# Print the modified dataset\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450df102-33e7-4a1b-b85e-bc251eb15f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ticker       2020_NI       2021_NI       2022_NI       2023_NI  \\\n",
      "0       A  7.190000e+08  1.210000e+09  1.254000e+09  1.240000e+09   \n",
      "1      AA -1.700000e+08  4.290000e+08 -1.230000e+08 -6.510000e+08   \n",
      "2     AAL -8.885000e+09 -1.993000e+09  1.270000e+08  8.220000e+08   \n",
      "3    AAME  1.216900e+07  4.281000e+06  1.525000e+06           NaN   \n",
      "4     AAN -2.659120e+08  1.099340e+08 -5.280000e+06  2.823000e+06   \n",
      "5    AAOI -5.845200e+07 -5.416200e+07 -6.639700e+07 -5.604800e+07   \n",
      "6    AAON  7.900900e+07  5.875800e+07  1.003760e+08  1.776230e+08   \n",
      "7     AAP  4.930210e+08  5.966150e+08  4.644020e+08  2.973500e+07   \n",
      "8    AAPL  5.741100e+10  9.468000e+10  9.980300e+10  9.699500e+10   \n",
      "9     AAT  3.558800e+07  3.659300e+07  5.587700e+07  6.469000e+07   \n",
      "10   ABBV  4.616000e+09  1.154200e+10  1.183600e+10  4.863000e+09   \n",
      "11   ABCB  2.619880e+08  3.769130e+08  3.465400e+08  2.691050e+08   \n",
      "12   ABEO -8.423400e+07 -8.493600e+07 -3.969600e+07 -5.418800e+07   \n",
      "13    ABG  2.544000e+08  5.324000e+08  9.973000e+08  6.025000e+08   \n",
      "14   ABIO -9.738000e+06 -1.932200e+07 -9.926000e+06 -5.339000e+06   \n",
      "15    ABM  3.000000e+05  1.263000e+08  2.304000e+08  2.513000e+08   \n",
      "16   ABMD           NaN  2.255250e+08  1.365050e+08           NaN   \n",
      "17    ABR  1.709490e+08  3.393000e+08  3.257830e+08  3.714340e+08   \n",
      "18    ABT  4.495000e+09  7.071000e+09  6.933000e+09  5.723000e+09   \n",
      "19     AC  1.881600e+07  5.920300e+07 -4.890700e+07  3.745100e+07   \n",
      "20    ACA  1.066000e+08  6.960000e+07  2.458000e+08  1.592000e+08   \n",
      "21   ACAD -2.815840e+08 -1.678700e+08 -2.159750e+08 -6.128600e+07   \n",
      "22   ACCO  6.200000e+07  1.019000e+08 -1.320000e+07 -2.180000e+07   \n",
      "23   ACGL  1.405521e+09  2.157000e+09  1.476000e+09  4.443000e+09   \n",
      "24   ACHC -6.721320e+08  1.906350e+08  2.731390e+08 -2.166700e+07   \n",
      "25   ACHV -1.473000e+07 -3.315200e+07 -4.235000e+07 -2.981500e+07   \n",
      "26   ACIW  7.266000e+07  1.277910e+08  1.421770e+08  1.215090e+08   \n",
      "27   ACLS  4.998200e+07  9.865000e+07  1.830790e+08  2.462630e+08   \n",
      "28    ACM -1.863700e+08  1.731850e+08  3.106110e+08  5.533200e+07   \n",
      "29   ACMR  1.878000e+07  3.775700e+07  3.926300e+07  7.734900e+07   \n",
      "30    ACN  5.107839e+09  5.906809e+09  6.877169e+09  6.871557e+09   \n",
      "31   ACNB  1.839400e+07  2.783400e+07  3.575200e+07  3.168800e+07   \n",
      "32   ACOR -9.959400e+07 -1.039540e+08 -6.591600e+07 -2.528540e+08   \n",
      "33   ACRE  2.184000e+07  6.046000e+07  2.978500e+07 -3.886700e+07   \n",
      "34   ACRS -5.101500e+07 -9.086500e+07 -8.690800e+07 -8.848100e+07   \n",
      "35   ACTG  1.092310e+08  1.491970e+08 -1.250650e+08  6.706000e+07   \n",
      "36    ACU  8.098766e+06  1.365568e+07  3.034766e+06  1.779316e+07   \n",
      "37   ADBE  5.260000e+09  4.822000e+09  4.756000e+09  5.428000e+09   \n",
      "38    ADC  9.138100e+07  1.222730e+08  1.524370e+08  1.699590e+08   \n",
      "39    ADI  1.220761e+09  1.390422e+09  2.748561e+09  3.314579e+09   \n",
      "40    ADM  1.772000e+09  2.709000e+09  4.340000e+09  3.483000e+09   \n",
      "41   ADMA -7.574855e+07 -7.164800e+07 -6.590400e+07 -2.823900e+07   \n",
      "42   ADNT -5.470000e+08  1.108000e+09 -1.200000e+08  2.050000e+08   \n",
      "43    ADP  2.466500e+09  2.598500e+09  2.948900e+09  3.412000e+09   \n",
      "44   ADSK           NaN  1.208000e+09  4.970000e+08  8.230000e+08   \n",
      "45    ADT -6.321930e+08 -3.408200e+08  1.326630e+08  4.630090e+08   \n",
      "46   ADTN  2.378000e+06 -8.635000e+06 -2.037000e+06 -2.676880e+08   \n",
      "47   ADUS  3.313300e+07  4.512600e+07  4.602500e+07  6.251600e+07   \n",
      "48   ADVM -1.175070e+08 -1.455400e+08 -1.545360e+08 -1.171650e+08   \n",
      "49   ADXS -3.014600e+07 -4.025400e+07 -3.801300e+07 -4.807200e+07   \n",
      "\n",
      "    2020_2021_NI_Grow  2021_2022_NI_Grow  2022_2023_NI_Grow  \\\n",
      "0        4.910000e+08       4.400000e+07      -1.400000e+07   \n",
      "1        5.990000e+08      -5.520000e+08      -5.280000e+08   \n",
      "2        6.892000e+09       2.120000e+09       6.950000e+08   \n",
      "3       -7.888000e+06      -2.756000e+06                NaN   \n",
      "4        3.758460e+08      -1.152140e+08       8.103000e+06   \n",
      "5        4.290000e+06      -1.223500e+07       1.034900e+07   \n",
      "6       -2.025100e+07       4.161800e+07       7.724700e+07   \n",
      "7        1.035940e+08      -1.322130e+08      -4.346670e+08   \n",
      "8        3.726900e+10       5.123000e+09      -2.808000e+09   \n",
      "9        1.005000e+06       1.928400e+07       8.813000e+06   \n",
      "10       6.926000e+09       2.940000e+08      -6.973000e+09   \n",
      "11       1.149250e+08      -3.037300e+07      -7.743500e+07   \n",
      "12      -7.020000e+05       4.524000e+07      -1.449200e+07   \n",
      "13       2.780000e+08       4.649000e+08      -3.948000e+08   \n",
      "14      -9.584000e+06       9.396000e+06       4.587000e+06   \n",
      "15       1.260000e+08       1.041000e+08       2.090000e+07   \n",
      "16                NaN      -8.902000e+07                NaN   \n",
      "17       1.683510e+08      -1.351700e+07       4.565100e+07   \n",
      "18       2.576000e+09      -1.380000e+08      -1.210000e+09   \n",
      "19       4.038700e+07      -1.081100e+08       8.635800e+07   \n",
      "20      -3.700000e+07       1.762000e+08      -8.660000e+07   \n",
      "21       1.137140e+08      -4.810500e+07       1.546890e+08   \n",
      "22       3.990000e+07      -1.151000e+08      -8.600000e+06   \n",
      "23       7.514790e+08      -6.810000e+08       2.967000e+09   \n",
      "24       8.627670e+08       8.250400e+07      -2.948060e+08   \n",
      "25      -1.842200e+07      -9.198000e+06       1.253500e+07   \n",
      "26       5.513100e+07       1.438600e+07      -2.066800e+07   \n",
      "27       4.866800e+07       8.442900e+07       6.318400e+07   \n",
      "28       3.595550e+08       1.374260e+08      -2.552790e+08   \n",
      "29       1.897700e+07       1.506000e+06       3.808600e+07   \n",
      "30       7.989700e+08       9.703600e+08      -5.612000e+06   \n",
      "31       9.440000e+06       7.918000e+06      -4.064000e+06   \n",
      "32      -4.360000e+06       3.803800e+07      -1.869380e+08   \n",
      "33       3.862000e+07      -3.067500e+07      -6.865200e+07   \n",
      "34      -3.985000e+07       3.957000e+06      -1.573000e+06   \n",
      "35       3.996600e+07      -2.742620e+08       1.921250e+08   \n",
      "36       5.556913e+06      -1.062091e+07       1.475839e+07   \n",
      "37      -4.380000e+08      -6.600000e+07       6.720000e+08   \n",
      "38       3.089200e+07       3.016400e+07       1.752200e+07   \n",
      "39       1.696610e+08       1.358139e+09       5.660180e+08   \n",
      "40       9.370000e+08       1.631000e+09      -8.570000e+08   \n",
      "41       4.100548e+06       5.744000e+06       3.766500e+07   \n",
      "42       1.655000e+09      -1.228000e+09       3.250000e+08   \n",
      "43       1.320000e+08       3.504000e+08       4.631000e+08   \n",
      "44                NaN      -7.110000e+08       3.260000e+08   \n",
      "45       2.913730e+08       4.734830e+08       3.303460e+08   \n",
      "46      -1.101300e+07       6.598000e+06      -2.656510e+08   \n",
      "47       1.199300e+07       8.990000e+05       1.649100e+07   \n",
      "48      -2.803300e+07      -8.996000e+06       3.737100e+07   \n",
      "49      -1.010800e+07       2.241000e+06      -1.005900e+07   \n",
      "\n",
      "               Gsector  \n",
      "0           Healthcare  \n",
      "1      Basic Materials  \n",
      "2          Industrials  \n",
      "3   Financial Services  \n",
      "4          Industrials  \n",
      "5           Technology  \n",
      "6          Industrials  \n",
      "7    Consumer Cyclical  \n",
      "8           Technology  \n",
      "9          Real Estate  \n",
      "10          Healthcare  \n",
      "11  Financial Services  \n",
      "12          Healthcare  \n",
      "13   Consumer Cyclical  \n",
      "14          Healthcare  \n",
      "15         Industrials  \n",
      "16                None  \n",
      "17         Real Estate  \n",
      "18          Healthcare  \n",
      "19  Financial Services  \n",
      "20         Industrials  \n",
      "21          Healthcare  \n",
      "22         Industrials  \n",
      "23  Financial Services  \n",
      "24          Healthcare  \n",
      "25          Healthcare  \n",
      "26          Technology  \n",
      "27          Technology  \n",
      "28         Industrials  \n",
      "29          Technology  \n",
      "30          Technology  \n",
      "31  Financial Services  \n",
      "32          Healthcare  \n",
      "33         Real Estate  \n",
      "34          Healthcare  \n",
      "35         Industrials  \n",
      "36  Consumer Defensive  \n",
      "37          Technology  \n",
      "38         Real Estate  \n",
      "39          Technology  \n",
      "40  Consumer Defensive  \n",
      "41          Healthcare  \n",
      "42   Consumer Cyclical  \n",
      "43         Industrials  \n",
      "44          Technology  \n",
      "45         Industrials  \n",
      "46          Technology  \n",
      "47          Healthcare  \n",
      "48          Healthcare  \n",
      "49          Healthcare  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv(\"modified_net_income_data.csv\")\n",
    "\n",
    "# Filter the dataset to only include the first 50 tickers\n",
    "data = data.head(50)\n",
    "\n",
    "# Function to get GICS sector from Yahoo Finance\n",
    "def get_gsector(ticker):\n",
    "    try:\n",
    "        # Fetch ticker data from Yahoo Finance\n",
    "        ticker_data = yf.Ticker(ticker)\n",
    "        # Get GICS sector\n",
    "        gsector = ticker_data.info['sector']\n",
    "        return gsector\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create the new column\n",
    "data['Gsector'] = data['Ticker'].apply(get_gsector)\n",
    "\n",
    "# Print the modified dataset\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6f7b5c-4813-4f99-8f9a-e209cccaff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ticker       2020_NI       2021_NI       2022_NI       2023_NI  \\\n",
      "0       A  7.190000e+08  1.210000e+09  1.254000e+09  1.240000e+09   \n",
      "1      AA -1.700000e+08  4.290000e+08 -1.230000e+08 -6.510000e+08   \n",
      "2     AAL -8.885000e+09 -1.993000e+09  1.270000e+08  8.220000e+08   \n",
      "3    AAME  1.216900e+07  4.281000e+06  1.525000e+06           NaN   \n",
      "4     AAN -2.659120e+08  1.099340e+08 -5.280000e+06  2.823000e+06   \n",
      "5    AAOI -5.845200e+07 -5.416200e+07 -6.639700e+07 -5.604800e+07   \n",
      "6    AAON  7.900900e+07  5.875800e+07  1.003760e+08  1.776230e+08   \n",
      "7     AAP  4.930210e+08  5.966150e+08  4.644020e+08  2.973500e+07   \n",
      "8    AAPL  5.741100e+10  9.468000e+10  9.980300e+10  9.699500e+10   \n",
      "9     AAT  3.558800e+07  3.659300e+07  5.587700e+07  6.469000e+07   \n",
      "10   ABBV  4.616000e+09  1.154200e+10  1.183600e+10  4.863000e+09   \n",
      "11   ABCB  2.619880e+08  3.769130e+08  3.465400e+08  2.691050e+08   \n",
      "12   ABEO -8.423400e+07 -8.493600e+07 -3.969600e+07 -5.418800e+07   \n",
      "13    ABG  2.544000e+08  5.324000e+08  9.973000e+08  6.025000e+08   \n",
      "14   ABIO -9.738000e+06 -1.932200e+07 -9.926000e+06 -5.339000e+06   \n",
      "15    ABM  3.000000e+05  1.263000e+08  2.304000e+08  2.513000e+08   \n",
      "16   ABMD           NaN  2.255250e+08  1.365050e+08           NaN   \n",
      "17    ABR  1.709490e+08  3.393000e+08  3.257830e+08  3.714340e+08   \n",
      "18    ABT  4.495000e+09  7.071000e+09  6.933000e+09  5.723000e+09   \n",
      "19     AC  1.881600e+07  5.920300e+07 -4.890700e+07  3.745100e+07   \n",
      "20    ACA  1.066000e+08  6.960000e+07  2.458000e+08  1.592000e+08   \n",
      "21   ACAD -2.815840e+08 -1.678700e+08 -2.159750e+08 -6.128600e+07   \n",
      "22   ACCO  6.200000e+07  1.019000e+08 -1.320000e+07 -2.180000e+07   \n",
      "23   ACGL  1.405521e+09  2.157000e+09  1.476000e+09  4.443000e+09   \n",
      "24   ACHC -6.721320e+08  1.906350e+08  2.731390e+08 -2.166700e+07   \n",
      "25   ACHV -1.473000e+07 -3.315200e+07 -4.235000e+07 -2.981500e+07   \n",
      "26   ACIW  7.266000e+07  1.277910e+08  1.421770e+08  1.215090e+08   \n",
      "27   ACLS  4.998200e+07  9.865000e+07  1.830790e+08  2.462630e+08   \n",
      "28    ACM -1.863700e+08  1.731850e+08  3.106110e+08  5.533200e+07   \n",
      "29   ACMR  1.878000e+07  3.775700e+07  3.926300e+07  7.734900e+07   \n",
      "30    ACN  5.107839e+09  5.906809e+09  6.877169e+09  6.871557e+09   \n",
      "31   ACNB  1.839400e+07  2.783400e+07  3.575200e+07  3.168800e+07   \n",
      "32   ACOR -9.959400e+07 -1.039540e+08 -6.591600e+07 -2.528540e+08   \n",
      "33   ACRE  2.184000e+07  6.046000e+07  2.978500e+07 -3.886700e+07   \n",
      "34   ACRS -5.101500e+07 -9.086500e+07 -8.690800e+07 -8.848100e+07   \n",
      "35   ACTG  1.092310e+08  1.491970e+08 -1.250650e+08  6.706000e+07   \n",
      "36    ACU  8.098766e+06  1.365568e+07  3.034766e+06  1.779316e+07   \n",
      "37   ADBE  5.260000e+09  4.822000e+09  4.756000e+09  5.428000e+09   \n",
      "38    ADC  9.138100e+07  1.222730e+08  1.524370e+08  1.699590e+08   \n",
      "39    ADI  1.220761e+09  1.390422e+09  2.748561e+09  3.314579e+09   \n",
      "40    ADM  1.772000e+09  2.709000e+09  4.340000e+09  3.483000e+09   \n",
      "41   ADMA -7.574855e+07 -7.164800e+07 -6.590400e+07 -2.823900e+07   \n",
      "42   ADNT -5.470000e+08  1.108000e+09 -1.200000e+08  2.050000e+08   \n",
      "43    ADP  2.466500e+09  2.598500e+09  2.948900e+09  3.412000e+09   \n",
      "44   ADSK           NaN  1.208000e+09  4.970000e+08  8.230000e+08   \n",
      "45    ADT -6.321930e+08 -3.408200e+08  1.326630e+08  4.630090e+08   \n",
      "46   ADTN  2.378000e+06 -8.635000e+06 -2.037000e+06 -2.676880e+08   \n",
      "47   ADUS  3.313300e+07  4.512600e+07  4.602500e+07  6.251600e+07   \n",
      "48   ADVM -1.175070e+08 -1.455400e+08 -1.545360e+08 -1.171650e+08   \n",
      "49   ADXS -3.014600e+07 -4.025400e+07 -3.801300e+07 -4.807200e+07   \n",
      "\n",
      "    2020_2021_NI_Grow  2021_2022_NI_Grow  2022_2023_NI_Grow  2023_MarketCap  \n",
      "0        4.910000e+08       4.400000e+07      -1.400000e+07     40831352832  \n",
      "1        5.990000e+08      -5.520000e+08      -5.280000e+08      6440781312  \n",
      "2        6.892000e+09       2.120000e+09       6.950000e+08      9086846976  \n",
      "3       -7.888000e+06      -2.756000e+06                NaN        38368564  \n",
      "4        3.758460e+08      -1.152140e+08       8.103000e+06       215909776  \n",
      "5        4.290000e+06      -1.223500e+07       1.034900e+07       387436832  \n",
      "6       -2.025100e+07       4.161800e+07       7.724700e+07      7801141760  \n",
      "7        1.035940e+08      -1.322130e+08      -4.346670e+08      4411132928  \n",
      "8        3.726900e+10       5.123000e+09      -2.808000e+09   2695306412032  \n",
      "9        1.005000e+06       1.928400e+07       8.813000e+06      1669862400  \n",
      "10       6.926000e+09       2.940000e+08      -6.973000e+09    287164006400  \n",
      "11       1.149250e+08      -3.037300e+07      -7.743500e+07      3320299008  \n",
      "12      -7.020000e+05       4.524000e+07      -1.449200e+07       106684504  \n",
      "13       2.780000e+08       4.649000e+08      -3.948000e+08      4305554432  \n",
      "14      -9.584000e+06       9.396000e+06       4.587000e+06        51418000  \n",
      "15       1.260000e+08       1.041000e+08       2.090000e+07      2783560192  \n",
      "16                NaN      -8.902000e+07                NaN     17180649472  \n",
      "17       1.683510e+08      -1.351700e+07       4.565100e+07      2457211392  \n",
      "18       2.576000e+09      -1.380000e+08      -1.210000e+09    184961515520  \n",
      "19       4.038700e+07      -1.081100e+08       8.635800e+07       688386176  \n",
      "20      -3.700000e+07       1.762000e+08      -8.660000e+07      3773737472  \n",
      "21       1.137140e+08      -4.810500e+07       1.546890e+08      2815059456  \n",
      "22       3.990000e+07      -1.151000e+08      -8.600000e+06       462775488  \n",
      "23       7.514790e+08      -6.810000e+08       2.967000e+09     34627993600  \n",
      "24       8.627670e+08       8.250400e+07      -2.948060e+08      6844286464  \n",
      "25      -1.842200e+07      -9.198000e+06       1.253500e+07       153448512  \n",
      "26       5.513100e+07       1.438600e+07      -2.066800e+07      3764650240  \n",
      "27       4.866800e+07       8.442900e+07       6.318400e+07      3427195904  \n",
      "28       3.595550e+08       1.374260e+08      -2.552790e+08     12828423168  \n",
      "29       1.897700e+07       1.506000e+06       3.808600e+07      1640747520  \n",
      "30       7.989700e+08       9.703600e+08      -5.612000e+06    189857300480  \n",
      "31       9.440000e+06       7.918000e+06      -4.064000e+06       281803552  \n",
      "32      -4.360000e+06       3.803800e+07      -1.869380e+08          821028  \n",
      "33       3.862000e+07      -3.067500e+07      -6.865200e+07       375548576  \n",
      "34      -3.985000e+07       3.957000e+06      -1.573000e+06        86528504  \n",
      "35       3.996600e+07      -2.742620e+08       1.921250e+08       489107552  \n",
      "36       5.556913e+06      -1.062091e+07       1.475839e+07       148906416  \n",
      "37      -4.380000e+08      -6.600000e+07       6.720000e+08    211664322560  \n",
      "38       3.089200e+07       3.016400e+07       1.752200e+07      5804995584  \n",
      "39       1.696610e+08       1.358139e+09       5.660180e+08    100907360256  \n",
      "40       9.370000e+08       1.631000e+09      -8.570000e+08     29222735872  \n",
      "41       4.100548e+06       5.744000e+06       3.766500e+07      1533171712  \n",
      "42       1.655000e+09      -1.228000e+09       3.250000e+08      2733727232  \n",
      "43       1.320000e+08       3.504000e+08       4.631000e+08    100200144896  \n",
      "44                NaN      -7.110000e+08       3.260000e+08     46498705408  \n",
      "45       2.913730e+08       4.734830e+08       3.303460e+08      5921982976  \n",
      "46      -1.101300e+07       6.598000e+06      -2.656510e+08       350482976  \n",
      "47       1.199300e+07       8.990000e+05       1.649100e+07      1534060800  \n",
      "48      -2.803300e+07      -8.996000e+06       3.737100e+07       214813216  \n",
      "49      -1.010800e+07       2.241000e+06      -1.005900e+07        28324944  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv(\"modified_net_income_data.csv\")\n",
    "\n",
    "# Filter the dataset to only include the first 50 tickers\n",
    "data = data.head(50)\n",
    "\n",
    "# Function to get market capitalization from Yahoo Finance\n",
    "def get_market_cap(ticker):\n",
    "    try:\n",
    "        # Fetch ticker data from Yahoo Finance\n",
    "        ticker_data = yf.Ticker(ticker)\n",
    "        # Get market cap\n",
    "        market_cap = ticker_data.info['marketCap']\n",
    "        return market_cap\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create the new column\n",
    "data['2023_MarketCap'] = data['Ticker'].apply(get_market_cap)\n",
    "\n",
    "# Print the modified dataset\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8463d324-2e9f-4e83-9558-47b76b6444ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'ticker_2023_PE.csv' has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv(\"modified_net_income_data.csv\")\n",
    "\n",
    "# Function to get forward PE ratio from Yahoo Finance\n",
    "def get_forward_pe(ticker):\n",
    "    try:\n",
    "        # Fetch ticker data from Yahoo Finance\n",
    "        ticker_data = yf.Ticker(ticker)\n",
    "        # Get forward PE ratio\n",
    "        forward_pe = ticker_data.info['forwardPE']\n",
    "        return forward_pe\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create the new column\n",
    "data['2023_PE'] = data['Ticker'].apply(get_forward_pe)\n",
    "\n",
    "# Create a new DataFrame with only 'Ticker' and '2023_PE' columns\n",
    "result_df = data[['Ticker', '2023_PE']]\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "result_df.to_csv(\"ticker_2023_PE.csv\", index=False)\n",
    "\n",
    "# Print a message to confirm the save\n",
    "print(\"CSV file 'ticker_2023_PE.csv' has been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb03da5-9efd-459b-a503-6b63697545e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'ticker_Gsector.csv' has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv(\"modified_net_income_data.csv\")\n",
    "\n",
    "# Function to get GICS sector from Yahoo Finance\n",
    "def get_gsector(ticker):\n",
    "    try:\n",
    "        # Fetch ticker data from Yahoo Finance\n",
    "        ticker_data = yf.Ticker(ticker)\n",
    "        # Get GICS sector\n",
    "        gsector = ticker_data.info['sector']\n",
    "        return gsector\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create the new column\n",
    "data['Gsector'] = data['Ticker'].apply(get_gsector)\n",
    "\n",
    "# Create a new DataFrame with only 'Ticker' and 'Gsector' columns\n",
    "result_df = data[['Ticker', 'Gsector']]\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "result_df.to_csv(\"ticker_Gsector.csv\", index=False)\n",
    "\n",
    "# Print a message to confirm the save\n",
    "print(\"CSV file 'ticker_Gsector.csv' has been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a919b0-dcb5-491b-8ee4-0cbbfb05004b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'ticker_2023_MarketCap.csv' has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv(\"modified_net_income_data.csv\")\n",
    "\n",
    "# Function to get market capitalization from Yahoo Finance\n",
    "def get_market_cap(ticker):\n",
    "    try:\n",
    "        # Fetch ticker data from Yahoo Finance\n",
    "        ticker_data = yf.Ticker(ticker)\n",
    "        # Get market cap\n",
    "        market_cap = ticker_data.info['marketCap']\n",
    "        return market_cap\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create the new column\n",
    "data['2023_MarketCap'] = data['Ticker'].apply(get_market_cap)\n",
    "\n",
    "# Create a new DataFrame with only 'Ticker' and '2023_MarketCap' columns\n",
    "result_df = data[['Ticker', '2023_MarketCap']]\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "result_df.to_csv(\"ticker_2023_MarketCap.csv\", index=False)\n",
    "\n",
    "# Print a message to confirm the save\n",
    "print(\"CSV file 'ticker_2023_MarketCap.csv' has been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e167b31e-9518-4b35-8657-174c2085d018",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to PE_Gsector.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from CSV files\n",
    "ticker_2023_PE_df = pd.read_csv(\"ticker_2023_PE.csv\")\n",
    "ticker_Gsector_df = pd.read_csv(\"ticker_Gsector.csv\")\n",
    "\n",
    "# Merge the two DataFrames based on the 'Ticker' column\n",
    "merged_df = pd.merge(ticker_2023_PE_df, ticker_Gsector_df, on=\"Ticker\")\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file labeled as \"PE_Gsector.csv\"\n",
    "merged_df.to_csv(\"PE_Gsector.csv\", index=False)\n",
    "\n",
    "print(\"Merged data saved to PE_Gsector.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be039db2-afef-40cf-b6b7-774049b732dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified data saved to PE_Gsector_with_avg.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from the merged CSV file\n",
    "merged_df = pd.read_csv(\"PE_Gsector.csv\")\n",
    "\n",
    "# Calculate average PE ratio by Gsector\n",
    "avg_pe_by_sector = merged_df.groupby('Gsector')['2023_PE'].mean().reset_index()\n",
    "avg_pe_by_sector.rename(columns={'2023_PE': 'Avg_PE_Gsector'}, inplace=True)\n",
    "\n",
    "# Merge the average PE ratios back into the original DataFrame based on Gsector\n",
    "merged_df = pd.merge(merged_df, avg_pe_by_sector, on=\"Gsector\")\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "merged_df.to_csv(\"PE_Gsector_with_avg.csv\", index=False)\n",
    "\n",
    "print(\"Modified data saved to PE_Gsector_with_avg.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54ed779b-4dc2-421f-b763-d6b0b721fffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified data saved to PE_Gsector_with_avg.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from the merged CSV file and drop rows with missing values\n",
    "merged_df = pd.read_csv(\"PE_Gsector.csv\").dropna()\n",
    "\n",
    "# Calculate average PE ratio by Gsector\n",
    "avg_pe_by_sector = merged_df.groupby('Gsector')['2023_PE'].mean().reset_index()\n",
    "avg_pe_by_sector.rename(columns={'2023_PE': 'Avg_PE_Gsector'}, inplace=True)\n",
    "\n",
    "# Merge the average PE ratios back into the original DataFrame based on Gsector\n",
    "merged_df = pd.merge(merged_df, avg_pe_by_sector, on=\"Gsector\")\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "merged_df.to_csv(\"PE_Gsector_with_avg.csv\", index=False)\n",
    "\n",
    "print(\"Modified data saved to PE_Gsector_with_avg.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a81ddfff-1e99-4d2f-95f3-3474ea9354ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Gsector    2023_PE\n",
      "0          Basic Materials  12.553481\n",
      "1   Communication Services        NaN\n",
      "2        Consumer Cyclical  14.477286\n",
      "3       Consumer Defensive  16.978318\n",
      "4                   Energy  12.364548\n",
      "5       Financial Services  12.598470\n",
      "6               Healthcare        NaN\n",
      "7              Industrials        NaN\n",
      "8              Real Estate        NaN\n",
      "9               Technology        NaN\n",
      "10               Utilities  17.248462\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from the merged CSV file\n",
    "merged_df = pd.read_csv(\"PE_Gsector.csv\")\n",
    "\n",
    "# Define the list of Gsectors\n",
    "gsectors = [\"Healthcare\", \"Basic Materials\", \"Industrials\", \"Financial Services\", \n",
    "            \"Technology\", \"Consumer Cyclical\", \"Real Estate\", \"Consumer Defensive\", \n",
    "            \"Energy\", \"Utilities\", \"Communication Services\"]\n",
    "\n",
    "# Calculate average PE ratio for each Gsector\n",
    "avg_pe_by_sector = merged_df.groupby('Gsector')['2023_PE'].mean().reset_index()\n",
    "\n",
    "# Filter only the desired Gsectors\n",
    "avg_pe_by_sector = avg_pe_by_sector[avg_pe_by_sector['Gsector'].isin(gsectors)]\n",
    "\n",
    "# Print the average PE ratio for each Gsector\n",
    "print(avg_pe_by_sector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94a91766-18e9-423e-a5ef-6bc51213496e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Gsector    2023_PE\n",
      "0          Basic Materials  12.553481\n",
      "1   Communication Services        NaN\n",
      "2        Consumer Cyclical  14.477286\n",
      "3       Consumer Defensive  16.978318\n",
      "4                   Energy  12.364548\n",
      "5       Financial Services  12.598470\n",
      "6               Healthcare        NaN\n",
      "7              Industrials        NaN\n",
      "8              Real Estate        NaN\n",
      "9               Technology        NaN\n",
      "10               Utilities  17.248462\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from the merged CSV file\n",
    "merged_df = pd.read_csv(\"PE_Gsector.csv\")\n",
    "\n",
    "# Define the list of Gsectors\n",
    "gsectors = [\"Healthcare\", \"Basic Materials\", \"Industrials\", \"Financial Services\", \n",
    "            \"Technology\", \"Consumer Cyclical\", \"Real Estate\", \"Consumer Defensive\", \n",
    "            \"Energy\", \"Utilities\", \"Communication Services\"]\n",
    "\n",
    "# Remove rows with missing values in the '2023_PE' column\n",
    "merged_df.dropna(subset=['2023_PE'], inplace=True)\n",
    "\n",
    "# Calculate average PE ratio for each Gsector\n",
    "avg_pe_by_sector = merged_df.groupby('Gsector')['2023_PE'].mean().reset_index()\n",
    "\n",
    "# Filter only the desired Gsectors\n",
    "avg_pe_by_sector = avg_pe_by_sector[avg_pe_by_sector['Gsector'].isin(gsectors)]\n",
    "\n",
    "# Print the average PE ratio for each Gsector\n",
    "print(avg_pe_by_sector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51201211-cb2e-41f0-8627-78e062563233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing sectors: set()\n"
     ]
    }
   ],
   "source": [
    "# Check which sectors are missing\n",
    "missing_sectors = set(gsectors) - set(avg_pe_by_sector['Gsector'])\n",
    "print(\"Missing sectors:\", missing_sectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "399019a9-45e9-4fe0-9dd8-961176b84a13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Gsector    2023_PE\n",
      "0          Basic Materials  12.553481\n",
      "1   Communication Services        NaN\n",
      "2        Consumer Cyclical  14.477286\n",
      "3       Consumer Defensive  16.978318\n",
      "4                   Energy  12.364548\n",
      "5       Financial Services  12.598470\n",
      "6               Healthcare        NaN\n",
      "7              Industrials        NaN\n",
      "8              Real Estate        NaN\n",
      "9               Technology        NaN\n",
      "10               Utilities  17.248462\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from the merged CSV file\n",
    "merged_df = pd.read_csv(\"PE_Gsector_with_avg.csv\")\n",
    "\n",
    "# Drop rows with missing values in the '2023_PE' column\n",
    "merged_df.dropna(subset=['2023_PE'], inplace=True)\n",
    "\n",
    "# Calculate average PE ratio for each Gsector\n",
    "avg_pe_by_sector = merged_df.groupby('Gsector')['2023_PE'].mean().reset_index()\n",
    "\n",
    "print(avg_pe_by_sector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3706abc5-7534-4ce9-8430-1f1df67083cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Gsector    2023_PE\n",
      "0          Basic Materials  12.553481\n",
      "1   Communication Services        NaN\n",
      "2        Consumer Cyclical  14.477286\n",
      "3       Consumer Defensive  16.978318\n",
      "4                   Energy  12.364548\n",
      "5       Financial Services  12.598470\n",
      "6               Healthcare        NaN\n",
      "7              Industrials        NaN\n",
      "8              Real Estate        NaN\n",
      "9               Technology        NaN\n",
      "10               Utilities  17.248462\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from the merged CSV file\n",
    "merged_df = pd.read_csv(\"PE_Gsector_with_avg.csv\")\n",
    "\n",
    "# Convert '2023_PE' column to numeric, coerce errors to NaN\n",
    "merged_df['2023_PE'] = pd.to_numeric(merged_df['2023_PE'], errors='coerce')\n",
    "\n",
    "# Drop rows with non-float values in the '2023_PE' column\n",
    "merged_df.dropna(subset=['2023_PE'], inplace=True)\n",
    "\n",
    "# Calculate average PE ratio for each Gsector\n",
    "avg_pe_by_sector = merged_df.groupby('Gsector')['2023_PE'].mean().reset_index()\n",
    "\n",
    "print(avg_pe_by_sector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aabad998-551f-49c2-a70a-4bc366755f31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Gsector    2023_PE\n",
      "0          Basic Materials  12.553481\n",
      "1   Communication Services        NaN\n",
      "2        Consumer Cyclical  14.477286\n",
      "3       Consumer Defensive  16.978318\n",
      "4                   Energy  12.364548\n",
      "5       Financial Services  12.598470\n",
      "6               Healthcare        NaN\n",
      "7              Industrials        NaN\n",
      "8              Real Estate        NaN\n",
      "9               Technology        NaN\n",
      "10               Utilities  17.248462\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from the merged CSV file\n",
    "merged_df = pd.read_csv(\"PE_Gsector_with_avg.csv\")\n",
    "\n",
    "# Convert '2023_PE' column to numeric, coerce errors to NaN\n",
    "merged_df['2023_PE'] = pd.to_numeric(merged_df['2023_PE'], errors='coerce')\n",
    "\n",
    "# Drop rows with non-float values in the '2023_PE' column\n",
    "merged_df.dropna(subset=['2023_PE'], inplace=True)\n",
    "\n",
    "# Drop rows with no PE value\n",
    "merged_df = merged_df.dropna(subset=['2023_PE'])\n",
    "\n",
    "# Calculate average PE ratio for each Gsector\n",
    "avg_pe_by_sector = merged_df.groupby('Gsector')['2023_PE'].mean().reset_index()\n",
    "\n",
    "print(avg_pe_by_sector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9379fba-7a42-4825-8c88-69cfe5062e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Gsector    2023_PE\n",
      "0          Basic Materials  12.553481\n",
      "1   Communication Services        NaN\n",
      "2        Consumer Cyclical  14.477286\n",
      "3       Consumer Defensive  16.978318\n",
      "4                   Energy  12.364548\n",
      "5       Financial Services  12.598470\n",
      "6               Healthcare        NaN\n",
      "7              Industrials        NaN\n",
      "8              Real Estate        NaN\n",
      "9               Technology        NaN\n",
      "10               Utilities  17.248462\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from the merged CSV file\n",
    "merged_df = pd.read_csv(\"PE_Gsector_with_avg.csv\")\n",
    "\n",
    "# Replace non-numeric values such as 'inf' and empty strings with NaN\n",
    "merged_df['2023_PE'] = pd.to_numeric(merged_df['2023_PE'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in the '2023_PE' column\n",
    "merged_df.dropna(subset=['2023_PE'], inplace=True)\n",
    "\n",
    "# Calculate average PE ratio for each Gsector\n",
    "avg_pe_by_sector = merged_df.groupby('Gsector')['2023_PE'].mean().reset_index()\n",
    "\n",
    "print(avg_pe_by_sector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46f5b65c-1d4a-4686-a681-0ca984d05c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2023_PE_Gsector_with_avg.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Calculate average PE ratio\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m average_pe \u001b[38;5;241m=\u001b[39m calculate_average_pe(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE_Gsector_with_avg.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Print result\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average_pe \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m, in \u001b[0;36mcalculate_average_pe\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_average_pe\u001b[39m(filename):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      6\u001b[0m         reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictReader(file, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# Initialize variables\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2023_PE_Gsector_with_avg.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Function to calculate average PE ratio\n",
    "def calculate_average_pe(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.DictReader(file, delimiter='\\t')\n",
    "        \n",
    "        # Initialize variables\n",
    "        total_pe = 0\n",
    "        valid_count = 0\n",
    "\n",
    "        # Iterate through rows\n",
    "        for row in reader:\n",
    "            pe_str = row['2023_PE']\n",
    "            # Check if PE ratio is valid (not 'inf' or '-')\n",
    "            if pe_str != 'inf' and pe_str != '-':\n",
    "                total_pe += float(pe_str)\n",
    "                valid_count += 1\n",
    "\n",
    "        # Calculate average PE ratio\n",
    "        if valid_count > 0:\n",
    "            average_pe = total_pe / valid_count\n",
    "            return average_pe\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Calculate average PE ratio\n",
    "average_pe = calculate_average_pe('2023_PE_Gsector_with_avg.csv')\n",
    "\n",
    "# Print result\n",
    "if average_pe is not None:\n",
    "    print(\"Average PE ratio for 2023:\", average_pe)\n",
    "else:\n",
    "    print(\"No valid PE ratios found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9888fe13-f379-4090-b263-22d10b962cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Gsector'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPE_Gsector_with_avg.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Calculate average PE ratio for each sector\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m avg_pe_by_sector \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGsector\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Fill in the Avg_PE_Gsector column based on the calculated averages\u001b[39;00m\n\u001b[1;32m     10\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg_PE_Gsector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGsector\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(avg_pe_by_sector)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   8250\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8253\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8254\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[1;32m   8255\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   8256\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   8257\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[1;32m   8258\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   8259\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[1;32m   8260\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[1;32m   8261\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[1;32m   8262\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[1;32m    932\u001b[0m         obj,\n\u001b[1;32m    933\u001b[0m         keys,\n\u001b[1;32m    934\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    935\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m    936\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    937\u001b[0m         observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[1;32m    938\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[1;32m    939\u001b[0m     )\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    983\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 985\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gsector'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"PE_Gsector_with_avg.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Calculate average PE ratio for each sector\n",
    "avg_pe_by_sector = df.groupby('Gsector')['2023_PE'].mean()\n",
    "\n",
    "# Fill in the Avg_PE_Gsector column based on the calculated averages\n",
    "df['Avg_PE_Gsector'] = df['Gsector'].map(avg_pe_by_sector)\n",
    "\n",
    "# Drop rows with improper values (e.g., negative PE ratios)\n",
    "df = df[df['2023_PE'] >= 0]\n",
    "\n",
    "# Save the cleaned DataFrame back to CSV\n",
    "df.to_csv(\"cleaned_PE_Gsector_with_avg.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bc45e1f-bff2-45f9-86d0-ab7f18f6fd6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ticker,2023_PE,Gsector,Avg_PE_Gsector'], dtype='object')\n",
      "  Ticker,2023_PE,Gsector,Avg_PE_Gsector\n",
      "0               A,22.831148,Healthcare,\n",
      "1            ABBV,13.412252,Healthcare,\n",
      "2           ABEO,-2.0078948,Healthcare,\n",
      "3          ABIO,-0.40292045,Healthcare,\n",
      "4             ABT,20.723736,Healthcare,\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e47edc22-459a-4007-9d32-792909a309f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the CSV file with comma as delimiter\n",
    "df = pd.read_csv(\"PE_Gsector_with_avg.csv\")\n",
    "\n",
    "# Calculate average PE ratio for each sector\n",
    "avg_pe_by_sector = df.groupby('Gsector')['2023_PE'].mean()\n",
    "\n",
    "# Fill in the Avg_PE_Gsector column based on the calculated averages\n",
    "df['Avg_PE_Gsector'] = df['Gsector'].map(avg_pe_by_sector)\n",
    "\n",
    "# Drop rows with improper values (e.g., negative PE ratios)\n",
    "df = df[df['2023_PE'] >= 0]\n",
    "\n",
    "# Save the cleaned DataFrame back to CSV\n",
    "df.to_csv(\"cleaned_PE_Gsector_with_avg.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2bd14b0-45aa-4ab2-a459-4b23e0bef21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with comma as delimiter\n",
    "df = pd.read_csv(\"PE_Gsector_with_avg.csv\")\n",
    "\n",
    "# Remove rows with \"inf\" values in 2023_PE column\n",
    "df = df[df['2023_PE'] != float('inf')]\n",
    "\n",
    "# Calculate average PE ratio for each sector\n",
    "avg_pe_by_sector = df.groupby('Gsector')['2023_PE'].mean()\n",
    "\n",
    "# Fill in the Avg_PE_Gsector column based on the calculated averages\n",
    "df['Avg_PE_Gsector'] = df['Gsector'].map(avg_pe_by_sector)\n",
    "\n",
    "# Save the cleaned DataFrame back to CSV\n",
    "df.to_csv(\"cleaned_PE_Gsector_with_avg.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63cb655a-4c36-44a3-85af-6592c4efcfec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Market Cap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Market Cap'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOther\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Apply categorization to the market cap column\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarket Cap Size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarket Cap\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(categorize_market_cap)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Group by market cap size and sum up market cap values\u001b[39;00m\n\u001b[1;32m     26\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarket Cap Size\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarket Cap\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Market Cap'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"ticker_2023_MarketCap.csv\")\n",
    "\n",
    "# Define the market cap size categories\n",
    "categories = {\n",
    "    'mega-cap': lambda x: x >= 200000000000,\n",
    "    'large-cap': lambda x: 10000000000 <= x < 200000000000,\n",
    "    'mid-cap': lambda x: 2000000000 <= x < 10000000000,\n",
    "    'small-cap': lambda x: 250000000 <= x < 2000000000,\n",
    "    'micro-cap': lambda x: x < 250000000\n",
    "}\n",
    "\n",
    "# Function to categorize market cap\n",
    "def categorize_market_cap(market_cap):\n",
    "    for category, condition in categories.items():\n",
    "        if condition(market_cap):\n",
    "            return category\n",
    "    return 'Other'\n",
    "\n",
    "# Apply categorization to the market cap column\n",
    "data['Market Cap Size'] = data['Market Cap'].apply(categorize_market_cap)\n",
    "\n",
    "# Group by market cap size and sum up market cap values\n",
    "grouped_data = data.groupby('Market Cap Size').agg({'Market Cap': 'sum'})\n",
    "\n",
    "# Print the grouped data\n",
    "print(grouped_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e76e3623-e443-4197-bbdd-68c713072b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 2023_MarketCap\n",
      "Market Cap Size                \n",
      "large-cap        22010460932096\n",
      "mega-cap         24008861351936\n",
      "micro-cap           54040462697\n",
      "mid-cap           3257538882816\n",
      "small-cap          643012293248\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"ticker_2023_MarketCap.csv\")\n",
    "\n",
    "# Define the market cap size categories\n",
    "categories = {\n",
    "    'mega-cap': lambda x: x >= 200000000000,\n",
    "    'large-cap': lambda x: 10000000000 <= x < 200000000000,\n",
    "    'mid-cap': lambda x: 2000000000 <= x < 10000000000,\n",
    "    'small-cap': lambda x: 250000000 <= x < 2000000000,\n",
    "    'micro-cap': lambda x: x < 250000000\n",
    "}\n",
    "\n",
    "# Function to categorize market cap\n",
    "def categorize_market_cap(market_cap):\n",
    "    for category, condition in categories.items():\n",
    "        if condition(market_cap):\n",
    "            return category\n",
    "    return 'Other'\n",
    "\n",
    "# Apply categorization to the market cap column\n",
    "data['Market Cap Size'] = data['2023_MarketCap'].apply(categorize_market_cap)\n",
    "\n",
    "# Group by market cap size and sum up market cap values\n",
    "grouped_data = data.groupby('Market Cap Size').agg({'2023_MarketCap': 'sum'})\n",
    "\n",
    "# Print the grouped data\n",
    "print(grouped_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d768527-32ea-497c-897b-64c394e71107",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Ticker  2023_MarketCap Market_Cap_Cat\n",
      "0         A     40807911424      large-cap\n",
      "1        AA      6412950016        mid-cap\n",
      "2       AAL      9062111232        mid-cap\n",
      "3      AAME        38368564      micro-cap\n",
      "4       AAN       214991008      micro-cap\n",
      "...     ...             ...            ...\n",
      "2578   USIO        39774540      micro-cap\n",
      "2579   VISL         9564498      micro-cap\n",
      "2580     WW       146528704      micro-cap\n",
      "2581   XFOR       189937888      micro-cap\n",
      "2582   ZYXI       363679296      small-cap\n",
      "\n",
      "[2583 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"ticker_2023_MarketCap.csv\")\n",
    "\n",
    "# Define the market cap size categories\n",
    "categories = {\n",
    "    'mega-cap': lambda x: x >= 200000000000,\n",
    "    'large-cap': lambda x: 10000000000 <= x < 200000000000,\n",
    "    'mid-cap': lambda x: 2000000000 <= x < 10000000000,\n",
    "    'small-cap': lambda x: 250000000 <= x < 2000000000,\n",
    "    'micro-cap': lambda x: x < 250000000\n",
    "}\n",
    "\n",
    "# Function to categorize market cap\n",
    "def categorize_market_cap(market_cap):\n",
    "    for category, condition in categories.items():\n",
    "        if condition(market_cap):\n",
    "            return category\n",
    "    return 'Other'\n",
    "\n",
    "# Apply categorization to the market cap column and create a new column for the category\n",
    "data['Market_Cap_Cat'] = data['2023_MarketCap'].apply(categorize_market_cap)\n",
    "\n",
    "# Print the DataFrame with the new column\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44915dae-1eff-470d-954c-6de7a2448940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New CSV file saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"ticker_2023_MarketCap.csv\")\n",
    "\n",
    "# Define the market cap size categories\n",
    "categories = {\n",
    "    'mega-cap': lambda x: x >= 200000000000,\n",
    "    'large-cap': lambda x: 10000000000 <= x < 200000000000,\n",
    "    'mid-cap': lambda x: 2000000000 <= x < 10000000000,\n",
    "    'small-cap': lambda x: 250000000 <= x < 2000000000,\n",
    "    'micro-cap': lambda x: x < 250000000\n",
    "}\n",
    "\n",
    "# Function to categorize market cap\n",
    "def categorize_market_cap(market_cap):\n",
    "    for category, condition in categories.items():\n",
    "        if condition(market_cap):\n",
    "            return category\n",
    "    return 'Other'\n",
    "\n",
    "# Apply categorization to the market cap column and create a new column for the category\n",
    "data['Market_Cap_Cat'] = data['2023_MarketCap'].apply(categorize_market_cap)\n",
    "\n",
    "# Save the DataFrame with the new column to a new CSV file\n",
    "data.to_csv(\"ticker_2023_MarketCap_with_Category.csv\", index=False)\n",
    "\n",
    "print(\"New CSV file saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e945162-6fee-40ef-8081-e6c784a57cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Ticker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q6/3lfkn2n54rs43hmys3vv8k1w0000gn/T/ipykernel_40051/3443639948.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnet_income_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"modified_net_income_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Merge the CSV files based on the 'Ticker' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmerged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarket_cap_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpe_gsector_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Ticker'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmerged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_income_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Ticker'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Save the merged data to a new CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmerged_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stalwart_Master.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 148\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    733\u001b[0m         (\n\u001b[1;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Ticker'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "market_cap_data = pd.read_csv(\"ticker_2023_MarketCap_with_Category.csv\")\n",
    "pe_gsector_data = pd.read_csv(\"cleaned_PE_Gsector_with_avg.csv\")\n",
    "net_income_data = pd.read_csv(\"modified_net_income_data.csv\")\n",
    "\n",
    "# Merge the CSV files based on the 'Ticker' column\n",
    "merged_data = pd.merge(market_cap_data, pe_gsector_data, on='Ticker', how='outer')\n",
    "merged_data = pd.merge(merged_data, net_income_data, on='Ticker', how='outer')\n",
    "\n",
    "# Save the merged data to a new CSV file\n",
    "merged_data.to_csv(\"Stalwart_Master.csv\", index=False)\n",
    "\n",
    "print(\"Merged CSV file saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e704595-363b-4ba6-bef4-d1caaa9a85fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV file saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "market_cap_data = pd.read_csv(\"ticker_2023_MarketCap_with_Category.csv\")\n",
    "pe_gsector_data = pd.read_csv(\"cleaned_PE_Gsector_with_avg.csv\")\n",
    "net_income_data = pd.read_csv(\"modified_net_income_data.csv\")\n",
    "\n",
    "# Rename the first column in net_income_data to \"Ticker\"\n",
    "net_income_data.rename(columns={net_income_data.columns[0]: 'Ticker'}, inplace=True)\n",
    "\n",
    "# Merge the CSV files based on the 'Ticker' column\n",
    "merged_data = pd.merge(market_cap_data, pe_gsector_data, on='Ticker', how='outer')\n",
    "merged_data = pd.merge(merged_data, net_income_data, on='Ticker', how='outer')\n",
    "\n",
    "# Save the merged data to a new CSV file\n",
    "merged_data.to_csv(\"Stalwart_Master.csv\", index=False)\n",
    "\n",
    "print(\"Merged CSV file saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8785ae6-c4ea-4545-98e2-5b4cbf902b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Ticker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q6/3lfkn2n54rs43hmys3vv8k1w0000gn/T/ipykernel_40051/2629203829.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Read the ticker_2023_PE.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpe_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ticker_2023_PE.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Merge the two dataframes on the 'ticker' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_income_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpe_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Ticker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Rename the 2023_PE column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'PE'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'2023_PE'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 148\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    733\u001b[0m         (\n\u001b[1;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1217\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m                         \u001b[0;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Ticker'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the modified_net_income_data.csv\n",
    "net_income_df = pd.read_csv(\"modified_net_income_data.csv\")\n",
    "\n",
    "# Remove columns 2020_NI, 2021_NI, 2022_NI, 2023_NI\n",
    "net_income_df.drop(columns=['2020_NI', '2021_NI', '2022_NI', '2023_NI'], inplace=True)\n",
    "\n",
    "# Read the ticker_2023_PE.csv\n",
    "pe_df = pd.read_csv(\"ticker_2023_PE.csv\")\n",
    "\n",
    "# Merge the two dataframes on the 'ticker' column\n",
    "merged_df = pd.merge(net_income_df, pe_df, on='Ticker')\n",
    "\n",
    "# Rename the 2023_PE column\n",
    "merged_df.rename(columns={'PE': '2023_PE'}, inplace=True)\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_df.to_csv(\"NI_Grow_PE.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98aaa2e3-7e7a-4f1f-aeee-4dd1a6a4f37b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the modified_net_income_data.csv with 'Ticker' as the index\n",
    "net_income_df = pd.read_csv(\"modified_net_income_data.csv\", index_col=0)\n",
    "\n",
    "# Rename the index to 'Ticker'\n",
    "net_income_df.index.name = 'Ticker'\n",
    "\n",
    "# Remove columns 2020_NI, 2021_NI, 2022_NI, 2023_NI\n",
    "net_income_df.drop(columns=['2020_NI', '2021_NI', '2022_NI', '2023_NI'], inplace=True)\n",
    "\n",
    "# Read the ticker_2023_PE.csv\n",
    "pe_df = pd.read_csv(\"ticker_2023_PE.csv\")\n",
    "\n",
    "# Merge the two dataframes on the 'Ticker' column\n",
    "merged_df = pd.merge(net_income_df, pe_df, on='Ticker')\n",
    "\n",
    "# Rename the 2023_PE column\n",
    "merged_df.rename(columns={'PE': '2023_PE'}, inplace=True)\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_df.to_csv(\"NI_Grow_PE.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c43f256-552e-4c5d-a581-c244bad5563f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"modified_net_income_data.csv\")\n",
    "\n",
    "# Rename the first column to \"Ticker\"\n",
    "df.rename(columns={df.columns[0]: \"Ticker\"}, inplace=True)\n",
    "\n",
    "# Write the modified DataFrame back to CSV\n",
    "df.to_csv(\"modified_net_income_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e504b4f-6449-4d7d-bf6c-336573ecbbaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the modified_net_income_data.csv\n",
    "net_income_df = pd.read_csv(\"modified_net_income_data.csv\")\n",
    "\n",
    "# Rename the first column to 'Ticker'\n",
    "net_income_df.rename(columns={net_income_df.columns[0]: 'Ticker'}, inplace=True)\n",
    "\n",
    "# Remove columns 2020_NI, 2021_NI, 2022_NI, 2023_NI\n",
    "net_income_df.drop(columns=['2020_NI', '2021_NI', '2022_NI', '2023_NI'], inplace=True)\n",
    "\n",
    "# Read the ticker_2023_PE.csv\n",
    "pe_df = pd.read_csv(\"ticker_2023_PE.csv\")\n",
    "\n",
    "# Merge the two dataframes on the 'Ticker' column\n",
    "merged_df = pd.merge(net_income_df, pe_df, on='Ticker')\n",
    "\n",
    "# Rename the 2023_PE column\n",
    "merged_df.rename(columns={'PE': '2023_PE'}, inplace=True)\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_df.to_csv(\"NI_Grow_PE.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44108830-6f38-494e-9590-36eed9870623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"NI_Grow_PE.csv\")\n",
    "\n",
    "# Calculate average growth rate for each row\n",
    "df['Average_Growth'] = df[['2020_2021_NI_Grow', '2021_2022_NI_Grow', '2022_2023_NI_Grow']].mean(axis=1)\n",
    "\n",
    "# Categorize the growth rate\n",
    "def categorize_growth(average_growth):\n",
    "    if 20 <= average_growth <= 25:\n",
    "        return 'Ideal 20% - 25%'\n",
    "    else:\n",
    "        return 'Not Ideal'\n",
    "\n",
    "df['Growth_Rate'] = df['Average_Growth'].apply(categorize_growth)\n",
    "\n",
    "# Save the updated CSV with the name \"Fast_Grower_Master.csv\"\n",
    "df.to_csv(\"Fast_Grower_Master.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc081c99-94ac-4170-9f4d-2a56ca3e85ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AAWW: 'Net Income'\n",
      "Error fetching data for AAXN: 'Net Income'\n",
      "Error fetching data for ABC: 'Net Income'\n",
      "Error fetching data for ABTX: 'Net Income'\n",
      "Error fetching data for ACBI: 'Net Income'\n",
      "Error fetching data for ACC: 'Net Income'\n",
      "Error fetching data for ACER: 'Net Income'\n",
      "Error fetching data for ACIA: 'Net Income'\n",
      "Error fetching data for ACRX: 'Net Income'\n",
      "Error fetching data for ACY: 'Net Income'\n",
      "Error fetching data for ADES: 'Net Income'\n",
      "Error fetching data for ADMP: 'Net Income'\n",
      "Error fetching data for ADMS: 'Net Income'\n",
      "Error fetching data for ADRO: 'Net Income'\n",
      "Error fetching data for ADS: 'Net Income'\n",
      "Error fetching data for ADSW: 'Net Income'\n",
      "Error fetching data for AEGN: 'Net Income'\n",
      "Error fetching data for AERI: 'Net Income'\n",
      "Error fetching data for AEY: 'Net Income'\n",
      "Error fetching data for AFH: 'Net Income'\n",
      "Error fetching data for AFI: 'Net Income'\n",
      "Error fetching data for AFIN: 'Net Income'\n",
      "Error fetching data for AGFS: 'Net Income'\n",
      "Error fetching data for AGLE: 'Net Income'\n",
      "Error fetching data for AGTC: 'Net Income'\n",
      "Error fetching data for AHC: 'Net Income'\n",
      "Error fetching data for AIMC: 'Net Income'\n",
      "Error fetching data for AIMT: 'Net Income'\n",
      "Error fetching data for AJRD: 'Net Income'\n",
      "Error fetching data for AKCA: 'Net Income'\n",
      "Error fetching data for AKER: 'Net Income'\n",
      "Error fetching data for ALBO: 'Net Income'\n",
      "Error fetching data for ALJJ: 'Net Income'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m tickers \u001b[38;5;241m=\u001b[39m wilshire_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Get net income data for all tickers\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m net_income_data \u001b[38;5;241m=\u001b[39m get_net_income(tickers)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Convert the dictionary to a DataFrame\u001b[39;00m\n\u001b[1;32m     30\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(net_income_data)\n",
      "Cell \u001b[0;32mIn[50], line 10\u001b[0m, in \u001b[0;36mget_net_income\u001b[0;34m(tickers)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m tickers:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# Fetch the financials data for the ticker\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m         fin_data \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mTicker(ticker)\u001b[38;5;241m.\u001b[39mfinancials\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# Get the net income for the last 20 years\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         net_income \u001b[38;5;241m=\u001b[39m fin_data\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNet Income\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m:]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yfinance/ticker.py:205\u001b[0m, in \u001b[0;36mTicker.financials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinancials\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mincome_stmt\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yfinance/ticker.py:189\u001b[0m, in \u001b[0;36mTicker.income_stmt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mincome_stmt\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_income_stmt(pretty\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yfinance/base.py:1879\u001b[0m, in \u001b[0;36mTickerBase.get_income_stmt\u001b[0;34m(self, proxy, as_dict, pretty, freq)\u001b[0m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1863\u001b[0m \u001b[38;5;124;03m:Parameters:\u001b[39;00m\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;124;03m    as_dict: bool\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1875\u001b[0m \u001b[38;5;124;03m        Default is None\u001b[39;00m\n\u001b[1;32m   1876\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fundamentals\u001b[38;5;241m.\u001b[39mproxy \u001b[38;5;241m=\u001b[39m proxy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy\n\u001b[0;32m-> 1879\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fundamentals\u001b[38;5;241m.\u001b[39mfinancials\u001b[38;5;241m.\u001b[39mget_income_time_series(freq\u001b[38;5;241m=\u001b[39mfreq, proxy\u001b[38;5;241m=\u001b[39mproxy)\n\u001b[1;32m   1881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretty:\n\u001b[1;32m   1882\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yfinance/scrapers/fundamentals.py:55\u001b[0m, in \u001b[0;36mFinancials.get_income_time_series\u001b[0;34m(self, freq, proxy)\u001b[0m\n\u001b[1;32m     53\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_income_time_series\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m freq \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[0;32m---> 55\u001b[0m     res[freq] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_time_series(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m\"\u001b[39m, freq, proxy)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res[freq]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yfinance/utils.py:103\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[0;32m--> 103\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yfinance/scrapers/fundamentals.py:85\u001b[0m, in \u001b[0;36mFinancials._fetch_time_series\u001b[0;34m(self, name, timescale, proxy)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIllegal argument: timescale must be one of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_timescales\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     statement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_financials_table(name, timescale, proxy)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m statement \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m statement\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yfinance/scrapers/fundamentals.py:101\u001b[0m, in \u001b[0;36mFinancials._create_financials_table\u001b[0;34m(self, name, timescale, proxy)\u001b[0m\n\u001b[1;32m     98\u001b[0m keys \u001b[38;5;241m=\u001b[39m const\u001b[38;5;241m.\u001b[39mfundamentals_keys[name]\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_financials_time_series(timescale, keys, proxy)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yfinance/scrapers/fundamentals.py:118\u001b[0m, in \u001b[0;36mFinancials.get_financials_time_series\u001b[0;34m(self, timescale, keys, proxy)\u001b[0m\n\u001b[1;32m    115\u001b[0m url \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m&period1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(start_dt\u001b[38;5;241m.\u001b[39mtimestamp())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&period2=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(end\u001b[38;5;241m.\u001b[39mtimestamp())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Step 3: fetch and reshape data\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m json_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcache_get(url\u001b[38;5;241m=\u001b[39murl, proxy\u001b[38;5;241m=\u001b[39mproxy)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    119\u001b[0m json_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json_str)\n\u001b[1;32m    120\u001b[0m data_raw \u001b[38;5;241m=\u001b[39m json_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeseries\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yfinance/data.py:28\u001b[0m, in \u001b[0;36mlru_cache_freezeargs.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mtuple\u001b[39m(arg) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args])\n\u001b[1;32m     27\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28mtuple\u001b[39m(v) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yfinance/data.py:387\u001b[0m, in \u001b[0;36mYfData.cache_get\u001b[0;34m(self, url, user_agent_headers, params, proxy, timeout)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;129m@lru_cache_freezeargs\u001b[39m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize\u001b[38;5;241m=\u001b[39mcache_maxsize)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcache_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, user_agent_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m):\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(url, user_agent_headers, params, proxy, timeout)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yfinance/utils.py:103\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[0;32m--> 103\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yfinance/data.py:367\u001b[0m, in \u001b[0;36mYfData.get\u001b[0;34m(self, url, user_agent_headers, params, proxy, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m     cookies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    359\u001b[0m request_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m: url,\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcrumbs},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m'\u001b[39m: user_agent_headers \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_agent_headers\n\u001b[1;32m    366\u001b[0m }\n\u001b[0;32m--> 367\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_args)\n\u001b[1;32m    368\u001b[0m utils\u001b[38;5;241m.\u001b[39mget_yf_logger()\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse code=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;66;03m# Retry with other cookie strategy\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def get_net_income(tickers):\n",
    "    net_income_data = {}\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Fetch the financials data for the ticker\n",
    "            fin_data = yf.Ticker(ticker).financials\n",
    "            # Get the net income for the last 20 years\n",
    "            net_income = fin_data.loc['Net Income'].iloc[-20:]\n",
    "            # Extract the year from the index and group by year\n",
    "            net_income.index = pd.to_datetime(net_income.index)\n",
    "            net_income = net_income.groupby(net_income.index.year).sum()\n",
    "            net_income_data[ticker] = net_income\n",
    "        except Exception as e:\n",
    "            # If there's an error fetching data, skip the ticker and print the error\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "    return net_income_data\n",
    "\n",
    "# Load tickers from the CSV file\n",
    "wilshire_df = pd.read_csv('Wilkshire_5000.csv')\n",
    "tickers = wilshire_df['Ticker'].tolist()\n",
    "\n",
    "# Get net income data for all tickers\n",
    "net_income_data = get_net_income(tickers)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(net_income_data)\n",
    "\n",
    "# Transpose the DataFrame to have tickers as columns\n",
    "df = df.T\n",
    "\n",
    "# Rename columns with year_NI format\n",
    "df.columns = [f\"{year}_NI\" for year in df.columns]\n",
    "\n",
    "# Define the directory for saving the CSV file\n",
    "save_directory = \"Inputs\"\n",
    "\n",
    "# Check if the directory exists, if not, create it\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "# Define the file path for saving the CSV file\n",
    "csv_file_path = os.path.join(save_directory, 'net_income_data_grouped.csv')\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(csv_file_path):\n",
    "    # Save the DataFrame to a CSV file in the Inputs folder\n",
    "    df.to_csv(csv_file_path)\n",
    "    print(f\"Net Income Data saved to '{csv_file_path}'.\")\n",
    "else:\n",
    "    print(\"Net Income Data already exists in the Inputs folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0098adbe-de1d-4b1d-b7d4-537393d44681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_clean.to_csv(\"Slow_Grow_Master_Clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "baed695c-955b-4e71-be17-d8a975ebd5fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_clean.to_csv(\"Slow_Grow_Master_Clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80e799b1-d7c0-4bf2-b9b5-ce3d555c2265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\", delimiter='\\t')  # assuming tab delimiter\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_clean.to_csv(\"Slow_Grow_Master_Clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f6c876e-f9ca-4a5d-8b44-60cfdd04d84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\", delimiter='\\t')  # assuming tab delimiter\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_clean.to_csv(\"Slow_Grow_Master_Clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a6a947b-b093-4d94-bb6a-52ccc5ed55da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_clean.to_csv(\"Slow_Grow_Master_Clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "959c5626-8dfe-4767-9676-62220e5591ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Remove rows with missing values (rows where any column has missing values)\n",
    "df_clean = df.dropna(how='all')\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_clean.to_csv(\"Slow_Grow_Master_Clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "84274247-fa96-4422-bb96-119daa7c354e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Remove rows with missing values (rows where any column has missing values)\n",
    "df_clean = df.dropna(how='all')\n",
    "\n",
    "# Remove rows with any values of 0\n",
    "df_clean = df_clean[(df_clean != 0).all(axis=1)]\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_clean.to_csv(\"Slow_Grow_Master_Clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a81aae6d-d6b2-4833-865d-e9c1a9d614da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Remove rows with any values of 0\n",
    "df_clean = df_clean[(df_clean != 0).all(axis=1)]\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_clean.to_csv(\"Slow_Grow_Master_Clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a822bd87-f559-4711-9f7a-01458f912c79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Ticker, 2020_NI, 2021_NI, 2022_NI, 2023_NI, 2024_NI, 2020_Div, 2021_Div, 2022_Div, 2023_Div, 2020_2021_Div_Grow, 2021_2022_Div_Grow, 2022_2023_Div_Grow]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the cleaned CSV file\n",
    "df_clean = pd.read_csv(\"Slow_Grow_Master_Clean.csv\")\n",
    "\n",
    "# Print out the DataFrame\n",
    "print(df_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "228b7153-05fe-433c-94a7-7c2812e79304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Fill empty values with NaNs\n",
    "df_filled = df.fillna(pd.NA)\n",
    "\n",
    "# Save the filled DataFrame back to a CSV file\n",
    "df_filled.to_csv(\"Filled_Slow_Grow_Master.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d76efe1-8c9c-494a-bbf5-699d76c622a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame, treating empty strings as NaNs\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\", na_values=\"\")\n",
    "\n",
    "# Fill empty values with NaNs\n",
    "df_filled = df.fillna(pd.NA)\n",
    "\n",
    "# Save the filled DataFrame back to a CSV file\n",
    "df_filled.to_csv(\"Filled_Slow_Grow_Master.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a89f99a-95c9-4b58-9b54-16116383658d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Create a dictionary to specify which values to replace with NaNs for each column\n",
    "na_values = {'Ticker': '', '2020_NI': '', '2021_NI': '', '2022_NI': '', '2023_NI': '', '2024_NI': '',\n",
    "             '2020_Div': '', '2021_Div': '', '2022_Div': '', '2023_Div': '',\n",
    "             '2020_2021_Div_Grow': '', '2021_2022_Div_Grow': '', '2022_2023_Div_Grow': ''}\n",
    "\n",
    "# Replace empty values with NaNs using the dictionary\n",
    "df_filled = df.replace(na_values, pd.NA)\n",
    "\n",
    "# Save the filled DataFrame back to a CSV file\n",
    "df_filled.to_csv(\"Filled_Slow_Grow_Master.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3fcd4140-4e24-4352-827c-572eec4e5a7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Create a dictionary to specify which values to replace with NaNs for each column\n",
    "na_values = {'Ticker': '', '2020_NI': '', '2021_NI': '', '2022_NI': '', '2023_NI': '', '2024_NI': '',\n",
    "             '2020_Div': '', '2021_Div': '', '2022_Div': '', '2023_Div': '',\n",
    "             '2020_2021_Div_Grow': '', '2021_2022_Div_Grow': '', '2022_2023_Div_Grow': ''}\n",
    "\n",
    "# Replace empty values with NaNs using the dictionary\n",
    "df_filled = df.replace(na_values, pd.NA)\n",
    "\n",
    "# Remove rows containing NaNs\n",
    "df_cleaned = df_filled.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame back to a CSV file\n",
    "df_cleaned.to_csv(\"Cleaned_Slow_Grow_Master.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d4ac5b05-14f9-44f8-a6c8-d26518a23b17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values by column:\n",
      "Ticker                   0\n",
      "2020_NI                215\n",
      "2021_NI                  4\n",
      "2022_NI                 11\n",
      "2023_NI                 73\n",
      "2024_NI               2489\n",
      "2020_Div              1236\n",
      "2021_Div              1297\n",
      "2022_Div              1949\n",
      "2023_Div              2331\n",
      "2020_2021_Div_Grow    1335\n",
      "2021_2022_Div_Grow    1966\n",
      "2022_2023_Div_Grow    2335\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Count missing values by column\n",
    "missing_values = df.isna().sum()\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv(\"Slow_Grow_Master_Clean.csv\", index=False)\n",
    "\n",
    "# Print missing values by column name\n",
    "print(\"Missing values by column:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "958b6b82-b4c9-4154-9117-7c68f734ccc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv(\"Slow_Grow_Master_Clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "053c27a7-8e39-4819-a2b0-a3ad236928e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_cleaned = df.dropna(how='all')\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv(\"Slow_Grow_Master_Clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "82e22827-cb61-4ad7-9ad3-9af5d15f121e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Drop the \"2024_NI\" column in-place\n",
    "df.drop(columns=[\"2024_NI\"], inplace=True)\n",
    "\n",
    "# Save the modified DataFrame back to the same CSV file\n",
    "df.to_csv(\"Slow_Grow_Master.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9a4af13-092a-4477-b860-785f3bf1c536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"Slow_Grow_Master.csv\")\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv(\"Clean_Slow_Grow_Master.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4e0ad577-ce29-489a-86d6-40c5dd8b6079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"Stalwart_Master.csv\")\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv(\"Clean_Stalwart_Master.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5c7c081e-45c5-48a0-80dc-5d012f4b15cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2020_2021_Div_Grow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '2020_2021_Div_Grow'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClean_Slow_Grow_Master.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Filter companies with positive or flat growing dividends for each year\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020_2021_Div_Grow\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m      8\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021_2022_Div_Grow\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m      9\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022_2023_Div_Grow\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Save the filtered data to a new CSV file\u001b[39;00m\n\u001b[1;32m     12\u001b[0m filtered_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScreened_Slow_Grow.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '2020_2021_Div_Grow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Slow_Grow_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Filter companies with positive or flat growing dividends for each year\n",
    "filtered_df = df[(df['2020_2021_Div_Grow'] >= 0) & \n",
    "                 (df['2021_2022_Div_Grow'] >= 0) & \n",
    "                 (df['2022_2023_Div_Grow'] >= 0)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Slow_Grow.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1fa31455-e77b-4331-a75b-6d88ea455098",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ticker,2020_NI,2021_NI,2022_NI,2023_NI,2020_Div,2021_Div,2022_Div,2023_Div,2020_2021_Div_Grow,2021_2022_Div_Grow,2022_2023_Div_Grow'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Slow_Grow_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Print column names\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "586c117f-c848-4897-9c33-917f4a619342",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ticker', '2020_NI', '2021_NI', '2022_NI', '2023_NI', '2020_Div',\n",
      "       '2021_Div', '2022_Div', '2023_Div', '2020_2021_Div_Grow',\n",
      "       '2021_2022_Div_Grow', '2022_2023_Div_Grow'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Slow_Grow_Master.csv\")\n",
    "\n",
    "# Print column names\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "487f9581-4397-4b3a-89ca-493271ba4a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Slow_Grow_Master.csv\")\n",
    "\n",
    "# Filter companies with positive or flat growing dividends for each year\n",
    "filtered_df = df[(df['2020_2021_Div_Grow'] >= 0) & \n",
    "                 (df['2021_2022_Div_Grow'] >= 0) & \n",
    "                 (df['2022_2023_Div_Grow'] >= 0)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Slow_Grow.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "43f38f56-1bf3-4362-b691-2459d4dda876",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Market_Cap_Cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Market_Cap_Cat'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 16\u001b[0m\n\u001b[1;32m      7\u001b[0m market_cap_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmega-cap\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmega cap\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlarge-cap\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlarge cap\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmall-cap\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmall cap\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Filter companies with Market_Cap_Cat as 'mega cap' or 'large cap'\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarket_Cap_Cat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmega-cap\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlarge-cap\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate average Net Income growth across the three years\u001b[39;00m\n\u001b[1;32m     19\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg_NI_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020_2021_NI_Grow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021_2022_NI_Grow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022_2023_NI_Grow\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Market_Cap_Cat'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Stalwart_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Map Market_Cap_Cat to corresponding market cap size\n",
    "market_cap_map = {\n",
    "    'mega-cap': 'mega cap',\n",
    "    'large-cap': 'large cap',\n",
    "    'mid-cap': 'mid cap',\n",
    "    'micro-cap': 'micro cap',\n",
    "    'small-cap': 'small cap'\n",
    "}\n",
    "\n",
    "# Filter companies with Market_Cap_Cat as 'mega cap' or 'large cap'\n",
    "filtered_df = df[df['Market_Cap_Cat'].isin(['mega-cap', 'large-cap'])]\n",
    "\n",
    "# Calculate average Net Income growth across the three years\n",
    "df['Avg_NI_Growth'] = df[['2020_2021_NI_Grow', '2021_2022_NI_Grow', '2022_2023_NI_Grow']].mean(axis=1)\n",
    "\n",
    "# Filter companies where average Net Income growth is between + or - 3% from the industry PE ratio\n",
    "filtered_df = filtered_df[(df['Avg_NI_Growth'] >= 0.97 * df['Avg_PE_Gsector']) & \n",
    "                          (df['Avg_NI_Growth'] <= 1.03 * df['Avg_PE_Gsector'])]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Stalwart.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "af5370ee-dd5e-41a2-8c3a-c348e1a0288f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ticker,2023_MarketCap,Market_Cap_Cat,2023_PE,Gsector,Avg_PE_Gsector,2020_NI,2021_NI,2022_NI,2023_NI,2020_2021_NI_Grow,2021_2022_NI_Grow,2022_2023_NI_Grow'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bd33dad7-4d7c-4f73-bf93-1db0955a671f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ticker', '2023_MarketCap', 'Market_Cap_Cat', '2023_PE', 'Gsector',\n",
      "       'Avg_PE_Gsector', '2020_NI', '2021_NI', '2022_NI', '2023_NI',\n",
      "       '2020_2021_NI_Grow', '2021_2022_NI_Grow', '2022_2023_NI_Grow'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with comma as separator\n",
    "df = pd.read_csv(\"Clean_Stalwart_Master.csv\")\n",
    "\n",
    "# Print column names\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "977ee20f-f489-4568-b49e-b1b98e75165a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q6/3lfkn2n54rs43hmys3vv8k1w0000gn/T/ipykernel_40051/2331094156.py:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  filtered_df = filtered_df[(df['Avg_NI_Growth'] >= 0.97 * df['Avg_PE_Gsector']) &\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Stalwart_Master.csv\")\n",
    "\n",
    "# Filter companies with Market_Cap_Cat as 'mega cap' or 'large cap'\n",
    "filtered_df = df[df['Market_Cap_Cat'].isin(['mega-cap', 'large-cap'])]\n",
    "\n",
    "# Calculate average Net Income growth across the three years\n",
    "df['Avg_NI_Growth'] = df[['2020_2021_NI_Grow', '2021_2022_NI_Grow', '2022_2023_NI_Grow']].mean(axis=1)\n",
    "\n",
    "# Filter companies where average Net Income growth is between + or - 3% from the industry PE ratio\n",
    "filtered_df = filtered_df[(df['Avg_NI_Growth'] >= 0.97 * df['Avg_PE_Gsector']) & \n",
    "                          (df['Avg_NI_Growth'] <= 1.03 * df['Avg_PE_Gsector'])]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Stalwart.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69e948f5-048a-4ff3-b431-96437d049601",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q6/3lfkn2n54rs43hmys3vv8k1w0000gn/T/ipykernel_40051/68331262.py:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  filtered_df = filtered_df[(df['Avg_NI_Growth'] >= 0.97 * df['Avg_PE_Gsector']) &\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Stalwart_Master.csv\")\n",
    "\n",
    "# Filter companies with Market_Cap_Cat as 'mega cap' or 'large cap'\n",
    "filtered_df = df[df['Market_Cap_Cat'].isin(['mega-cap', 'large-cap'])]\n",
    "\n",
    "# Calculate average Net Income growth across the three years\n",
    "df['Avg_NI_Growth'] = df[['2020_2021_NI_Grow', '2021_2022_NI_Grow', '2022_2023_NI_Grow']].mean(axis=1)\n",
    "\n",
    "# Filter companies where average Net Income growth is between + or - 3% from the industry PE ratio\n",
    "filtered_df = filtered_df[(df['Avg_NI_Growth'] >= 0.97 * df['Avg_PE_Gsector']) & \n",
    "                          (df['Avg_NI_Growth'] <= 1.03 * df['Avg_PE_Gsector'])]\n",
    "\n",
    "# Add a new column for average NI growth\n",
    "filtered_df['Avg_NI_Growth'] = filtered_df[['2020_2021_NI_Grow', '2021_2022_NI_Grow', '2022_2023_NI_Grow']].mean(axis=1)\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Stalwart.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4065c6a5-3c7f-4926-bddb-315fbed86eba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Growth_Rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Growth_Rate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClean_Fast_Grower_Master.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Filter companies where the growth rate is ideal and the growth rate is within +3 or -3 from the PE of the stock\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrowth_Rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIdeal\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m      8\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m      9\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     10\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     11\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Save the filtered data to a new CSV file\u001b[39;00m\n\u001b[1;32m     14\u001b[0m filtered_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScreened_Fast_Grower.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Growth_Rate'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Filter companies where the growth rate is ideal and the growth rate is within +3 or -3 from the PE of the stock\n",
    "filtered_df = df[(df['Growth_Rate'] == 'Ideal') & \n",
    "                 (df['Average_Growth'] >= 20) & \n",
    "                 (df['Average_Growth'] <= 25) &\n",
    "                 (df['Average_Growth'] >= df['2023_PE'] - 3) & \n",
    "                 (df['Average_Growth'] <= df['2023_PE'] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "42d09625-2476-45fc-8fab-b74b774b09a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ticker,2020_2021_NI_Grow,2021_2022_NI_Grow,2022_2023_NI_Grow,2023_PE,Average_Growth,Growth_Rate'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Print column names\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "56a26a53-622c-4ef0-8bcb-e9b515d9930e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 7 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m column_names \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Rename the DataFrame columns\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m column_names\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Filter companies where the growth rate is ideal and the growth rate is within +3 or -3 from the PE of the stock\u001b[39;00m\n\u001b[1;32m     13\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrowth_Rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIdeal\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     14\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     15\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     16\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     17\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 7 elements"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Extract individual column names\n",
    "column_names = df.columns[0].split(',')\n",
    "\n",
    "# Rename the DataFrame columns\n",
    "df.columns = column_names\n",
    "\n",
    "# Filter companies where the growth rate is ideal and the growth rate is within +3 or -3 from the PE of the stock\n",
    "filtered_df = df[(df['Growth_Rate'] == 'Ideal') & \n",
    "                 (df['Average_Growth'] >= 20) & \n",
    "                 (df['Average_Growth'] <= 25) &\n",
    "                 (df['Average_Growth'] >= df['2023_PE'] - 3) & \n",
    "                 (df['Average_Growth'] <= df['2023_PE'] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9d229f19-b735-4874-acc1-cf4cf13ad2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ticker,2020_2021_NI_Grow,2021_2022_NI_Grow,2022_2023_NI_Grow,2023_PE,Average_Growth,Growth_Rate'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Print column names\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9dfa388-8a00-4fb6-96a4-66302652f4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 7 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m column_names \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Assign the column names to the DataFrame\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m column_names\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Filter companies where the growth rate is ideal and the average growth rate is within +3 or -3 from the PE of the stock\u001b[39;00m\n\u001b[1;32m     13\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrowth_Rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIdeal\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     14\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     15\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     16\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     17\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 7 elements"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Split the concatenated column names into individual names\n",
    "column_names = df.columns[0].split(',')\n",
    "\n",
    "# Assign the column names to the DataFrame\n",
    "df.columns = column_names\n",
    "\n",
    "# Filter companies where the growth rate is ideal and the average growth rate is within +3 or -3 from the PE of the stock\n",
    "filtered_df = df[(df['Growth_Rate'] == 'Ideal') & \n",
    "                 (df['Average_Growth'] >= 20) & \n",
    "                 (df['Average_Growth'] <= 25) &\n",
    "                 (df['Average_Growth'] >= df['2023_PE'] - 3) & \n",
    "                 (df['Average_Growth'] <= df['2023_PE'] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b3d19fc6-c847-4696-af4b-8fd562cd32fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 7 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m column_names \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Assign the column names to the DataFrame\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m column_names\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Filter rows where the \"Growth_Rate\" column is \"Ideal 20% - 25%\" and average growth rate is within +3 or -3 from the PE ratio\u001b[39;00m\n\u001b[1;32m     13\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrowth_Rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIdeal 20\u001b[39m\u001b[38;5;132;01m% - 25%\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     14\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     15\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 7 elements"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Split the concatenated column names into individual names\n",
    "column_names = df.columns[0].split(',')\n",
    "\n",
    "# Assign the column names to the DataFrame\n",
    "df.columns = column_names\n",
    "\n",
    "# Filter rows where the \"Growth_Rate\" column is \"Ideal 20% - 25%\" and average growth rate is within +3 or -3 from the PE ratio\n",
    "filtered_df = df[(df['Growth_Rate'] == 'Ideal 20% - 25%') & \n",
    "                 (df['Average_Growth'] >= df['2023_PE'] - 3) & \n",
    "                 (df['Average_Growth'] <= df['2023_PE'] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e68f5e36-e1c6-4d7d-8e6f-ce595b6f878b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 7 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m column_names \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Assign the column names to the DataFrame\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m column_names\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Filter rows where the \"Growth_Rate\" column is \"Ideal 20% - 25%\" and average growth rate is within +3 or -3 from the PE ratio\u001b[39;00m\n\u001b[1;32m     13\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrowth_Rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIdeal 20\u001b[39m\u001b[38;5;132;01m% - 25%\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     14\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     15\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 7 elements"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Extract individual column names from the first row\n",
    "column_names = df.columns[0].split(',')\n",
    "\n",
    "# Assign the column names to the DataFrame\n",
    "df.columns = column_names\n",
    "\n",
    "# Filter rows where the \"Growth_Rate\" column is \"Ideal 20% - 25%\" and average growth rate is within +3 or -3 from the PE ratio\n",
    "filtered_df = df[(df['Growth_Rate'] == 'Ideal 20% - 25%') & \n",
    "                 (df['Average_Growth'] >= df['2023_PE'] - 3) & \n",
    "                 (df['Average_Growth'] <= df['2023_PE'] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e8543b8e-337b-490d-a272-35355cb2d6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Growth_Rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Growth_Rate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m column_names\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Filter rows where the \"Growth_Rate\" column is \"Ideal 20% - 25%\" and average growth rate is within +3 or -3 from the PE ratio\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrowth_Rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIdeal 20\u001b[39m\u001b[38;5;132;01m% - 25%\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     14\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     15\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Save the filtered data to a new CSV file\u001b[39;00m\n\u001b[1;32m     18\u001b[0m filtered_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScreened_Fast_Grower.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Growth_Rate'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Extract individual column names from the first row and split them using the appropriate separator\n",
    "column_names = df.columns[0].split('\\t')\n",
    "\n",
    "# Assign the column names to the DataFrame\n",
    "df.columns = column_names\n",
    "\n",
    "# Filter rows where the \"Growth_Rate\" column is \"Ideal 20% - 25%\" and average growth rate is within +3 or -3 from the PE ratio\n",
    "filtered_df = df[(df['Growth_Rate'] == 'Ideal 20% - 25%') & \n",
    "                 (df['Average_Growth'] >= df['2023_PE'] - 3) & \n",
    "                 (df['Average_Growth'] <= df['2023_PE'] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "49c8d698-9d89-4d3e-92ff-cb08f51b02b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ticker,2020_2021_NI_Grow,2021_2022_NI_Grow,2022_2023_NI_Grow,2023_PE,Average_Growth,Growth_Rate'], dtype='object')\n",
      "The 'Growth_Rate' column does not exist in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Print column names\n",
    "print(df.columns)\n",
    "\n",
    "# Check if 'Growth_Rate' column exists in the DataFrame\n",
    "if 'Growth_Rate' in df.columns:\n",
    "    print(\"The 'Growth_Rate' column exists in the DataFrame.\")\n",
    "else:\n",
    "    print(\"The 'Growth_Rate' column does not exist in the DataFrame.\")\n",
    "\n",
    "# Insp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "233785f1-6588-40d8-9590-faac61360667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ticker', '2020_2021_NI_Grow', '2021_2022_NI_Grow', '2022_2023_NI_Grow', '2023_PE', 'Average_Growth', 'Growth_Rate']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 7 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(column_names)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Assign the split column names to the DataFrame\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m column_names\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Print the first few rows of the DataFrame to inspect the data\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 7 elements"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Split the concatenated column names into individual names\n",
    "column_names = df.columns[0].split(',')\n",
    "\n",
    "# Print the split column names\n",
    "print(column_names)\n",
    "\n",
    "# Assign the split column names to the DataFrame\n",
    "df.columns = column_names\n",
    "\n",
    "# Print the first few rows of the DataFrame to inspect the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d23e39dd-0842-4f7d-93df-2db673e0c7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ticker,2020_2021_NI_Grow,2021_2022_NI_Grow,2022_2023_NI_Grow,2023_PE,Average_Growth,Growth_Rate\n",
      "0  A,68.2893,3.6364,-1.1164,22.831148,23.6031,Ide...                                             \n",
      "1  AA,-352.3529,-128.6713,429.2683,15.792951,-17....                                             \n",
      "2  AAL,-77.5689,-106.3723,547.2441,4.3128037,121....                                             \n",
      "3  AAN,-141.3422,-104.8029,-153.4659,10.308824,-1...                                             \n",
      "4  AAOI,-7.3394,22.5896,-15.5865,11.614942,-0.112...                                             \n"
     ]
    }
   ],
   "source": [
    "# Print the first few rows of the DataFrame to inspect the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8c9a2301-62f4-43a7-bec4-19aca9539712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the CSV file with the correct separator\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f80a2a8f-e042-4792-84ac-35f6d42b6586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 7 elements, new values have 1 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m column_names \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Assign the split column names to the DataFrame\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m column_names\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Filter rows where the \"Growth_Rate\" column is \"Ideal 20% - 25%\" and average growth rate is within +3 or -3 from the PE ratio\u001b[39;00m\n\u001b[1;32m     13\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrowth_Rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIdeal 20\u001b[39m\u001b[38;5;132;01m% - 25%\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     14\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     15\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 7 elements, new values have 1 elements"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with the correct separator\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\",\")\n",
    "\n",
    "# Split the concatenated column names into individual names\n",
    "column_names = df.columns[0].split(',')\n",
    "\n",
    "# Assign the split column names to the DataFrame\n",
    "df.columns = column_names\n",
    "\n",
    "# Filter rows where the \"Growth_Rate\" column is \"Ideal 20% - 25%\" and average growth rate is within +3 or -3 from the PE ratio\n",
    "filtered_df = df[(df['Growth_Rate'] == 'Ideal 20% - 25%') & \n",
    "                 (df['Average_Growth'] >= df['2023_PE'] - 3) & \n",
    "                 (df['Average_Growth'] <= df['2023_PE'] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "48e53cd8-6e1e-4f63-be59-ec754ea288ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 7 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m column_names \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Assign the split column names to the DataFrame\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m column_names\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\u001b[39;00m\n\u001b[1;32m     13\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     14\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     15\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     16\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 7 elements"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Split the concatenated column names into individual names\n",
    "column_names = df.columns[0].split(',')\n",
    "\n",
    "# Assign the split column names to the DataFrame\n",
    "df.columns = column_names\n",
    "\n",
    "# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\n",
    "filtered_df = df[(df['Average_Growth'] >= 20) & \n",
    "                 (df['Average_Growth'] <= 25) &\n",
    "                 (df['Average_Growth'] >= df['2023_PE'] - 3) & \n",
    "                 (df['Average_Growth'] <= df['2023_PE'] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f180161-ac97-4d70-9147-7280a82fc44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 7 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m column_names \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Assign the column names to the DataFrame\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m column_names\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\u001b[39;00m\n\u001b[1;32m     13\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     14\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     15\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     16\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 7 elements"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Extract individual column names from the first row\n",
    "column_names = df.columns[0].split(',')\n",
    "\n",
    "# Assign the column names to the DataFrame\n",
    "df.columns = column_names\n",
    "\n",
    "# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\n",
    "filtered_df = df[(df['Average_Growth'] >= 20) & \n",
    "                 (df['Average_Growth'] <= 25) &\n",
    "                 (df['Average_Growth'] >= df['2023_PE'] - 3) & \n",
    "                 (df['Average_Growth'] <= df['2023_PE'] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ed7de832-df72-4af7-bb85-3cb7351a250e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Average_Growth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Average_Growth'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClean_Fast_Grower_Master.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m      8\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m      9\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     10\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Save the filtered data to a new CSV file\u001b[39;00m\n\u001b[1;32m     13\u001b[0m filtered_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScreened_Fast_Grower.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Average_Growth'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\n",
    "filtered_df = df[(df['Average_Growth'] >= 20) & \n",
    "                 (df['Average_Growth'] <= 25) &\n",
    "                 (df['Average_Growth'] >= df['2023_PE'] - 3) & \n",
    "                 (df['Average_Growth'] <= df['2023_PE'] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3badd460-2442-4087-acd8-57ca71933be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClean_Fast_Grower_Master.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m      8\u001b[0m                  (df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m      9\u001b[0m                  (df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     10\u001b[0m                  (df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Save the filtered data to a new CSV file\u001b[39;00m\n\u001b[1;32m     13\u001b[0m filtered_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScreened_Fast_Grower.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1096\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1097\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1594\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m-> 1594\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1596\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:904\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 904\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(k, i)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    907\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation based indexing can only have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    908\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] types\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1496\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(key):\n\u001b[0;32m-> 1496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;66;03m# a tuple should already have been caught by this point\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;66;03m# so don't treat a tuple as a valid indexer\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indexers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1589\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1587\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1589\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\n",
    "filtered_df = df[(df.iloc[:, 5] >= 20) & \n",
    "                 (df.iloc[:, 5] <= 25) &\n",
    "                 (df.iloc[:, 5] >= df.iloc[:, 4] - 3) & \n",
    "                 (df.iloc[:, 5] <= df.iloc[:, 4] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba8429d6-16e9-4608-9dd3-252ee1480d29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 1\n",
      "Column at position 0: Ticker,2020_2021_NI_Grow,2021_2022_NI_Grow,2022_2023_NI_Grow,2023_PE,Average_Growth,Growth_Rate\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn at position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     13\u001b[0m                  (df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     14\u001b[0m                  (df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     15\u001b[0m                  (df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Save the filtered data to a new CSV file\u001b[39;00m\n\u001b[1;32m     18\u001b[0m filtered_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScreened_Fast_Grower.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1096\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1097\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1594\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m-> 1594\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1596\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:904\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 904\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(k, i)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    907\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation based indexing can only have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    908\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] types\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1496\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(key):\n\u001b[0;32m-> 1496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;66;03m# a tuple should already have been caught by this point\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;66;03m# so don't treat a tuple as a valid indexer\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indexers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1589\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1587\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1589\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Print the number of columns and their positions\n",
    "print(\"Number of columns:\", len(df.columns))\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"Column at position {i}: {col}\")\n",
    "\n",
    "# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\n",
    "filtered_df = df[(df.iloc[:, 5] >= 20) & \n",
    "                 (df.iloc[:, 5] <= 25) &\n",
    "                 (df.iloc[:, 5] >= df.iloc[:, 4] - 3) & \n",
    "                 (df.iloc[:, 5] <= df.iloc[:, 4] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "19f085cb-f472-42ab-a30e-48c2c56c6a93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 1\n",
      "Column at position 0: Ticker,2020_2021_NI_Grow,2021_2022_NI_Grow,2022_2023_NI_Grow,2023_PE,Average_Growth,Growth_Rate\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn at position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     13\u001b[0m                  (df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     14\u001b[0m                  (df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     15\u001b[0m                  (df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Save the filtered data to a new CSV file\u001b[39;00m\n\u001b[1;32m     18\u001b[0m filtered_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScreened_Fast_Grower.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1096\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1097\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1594\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m-> 1594\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1596\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:904\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 904\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(k, i)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    907\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation based indexing can only have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    908\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] types\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1496\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(key):\n\u001b[0;32m-> 1496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;66;03m# a tuple should already have been caught by this point\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;66;03m# so don't treat a tuple as a valid indexer\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indexers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1589\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1587\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1589\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with the correct separator\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Print the number of columns and their positions\n",
    "print(\"Number of columns:\", len(df.columns))\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"Column at position {i}: {col}\")\n",
    "\n",
    "# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\n",
    "filtered_df = df[(df.iloc[:, 5] >= 20) & \n",
    "                 (df.iloc[:, 5] <= 25) &\n",
    "                 (df.iloc[:, 5] >= df.iloc[:, 4] - 3) & \n",
    "                 (df.iloc[:, 5] <= df.iloc[:, 4] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "72be6d49-1dbd-49f0-8b0f-9d155ad4f746",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m new_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m column_names\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m new_df[(new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     17\u001b[0m                      (new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     18\u001b[0m                      (new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     19\u001b[0m                      (new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage_Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_PE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Save the filtered data to a new CSV file\u001b[39;00m\n\u001b[1;32m     22\u001b[0m filtered_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScreened_Fast_Grower.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:60\u001b[0m, in \u001b[0;36mOpsMixin.__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ge__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39mge)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:6096\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6093\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6095\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6096\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   6098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:293\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:82\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/ops.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Split the concatenated column names into individual names\n",
    "column_names = df.columns[0].split(',')\n",
    "\n",
    "# Create a new DataFrame with the split values\n",
    "new_df = df.iloc[:, 0].str.split(',', expand=True)\n",
    "\n",
    "# Assign the split column names to the new DataFrame\n",
    "new_df.columns = column_names\n",
    "\n",
    "# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\n",
    "filtered_df = new_df[(new_df['Average_Growth'] >= 20) & \n",
    "                     (new_df['Average_Growth'] <= 25) &\n",
    "                     (new_df['Average_Growth'] >= new_df['2023_PE'] - 3) & \n",
    "                     (new_df['Average_Growth'] <= new_df['2023_PE'] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "78565e2f-fbfe-4586-ace7-98dfbad67202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"Clean_Fast_Grower_Master.csv\", sep=\"\\t\")\n",
    "\n",
    "# Split the concatenated column names into individual names\n",
    "column_names = df.columns[0].split(',')\n",
    "\n",
    "# Create a new DataFrame with the split values\n",
    "new_df = df.iloc[:, 0].str.split(',', expand=True)\n",
    "\n",
    "# Assign the split column names to the new DataFrame\n",
    "new_df.columns = column_names\n",
    "\n",
    "# Convert 'Average_Growth' and '2023_PE' columns to numeric\n",
    "new_df['Average_Growth'] = pd.to_numeric(new_df['Average_Growth'], errors='coerce')\n",
    "new_df['2023_PE'] = pd.to_numeric(new_df['2023_PE'], errors='coerce')\n",
    "\n",
    "# Filter rows where the average growth rate is between 20% and 25% and within +3 or -3 from the PE ratio\n",
    "filtered_df = new_df[(new_df['Average_Growth'] >= 20) & \n",
    "                     (new_df['Average_Growth'] <= 25) &\n",
    "                     (new_df['Average_Growth'] >= new_df['2023_PE'] - 3) & \n",
    "                     (new_df['Average_Growth'] <= new_df['2023_PE'] + 3)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(\"Screened_Fast_Grower.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
